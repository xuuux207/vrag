"""
å®éªŒ3 v3 ç»“æœåˆ†æè„šæœ¬
ä½¿ç”¨LLMè¯„åˆ†çš„ä¼˜åŒ–ç‰ˆæœ¬åˆ†æ
"""

import json
import sys
from pathlib import Path
from typing import Dict, List
import statistics


def load_latest_v3_results() -> List[Dict]:
    """åŠ è½½æœ€æ–°çš„v3å®éªŒç»“æœ"""
    output_dir = Path(__file__).parent.parent / "outputs"

    result_files = list(output_dir.glob("experiment3_v3_results_*.json"))
    if not result_files:
        print("âŒ æœªæ‰¾åˆ°v3å®éªŒç»“æœæ–‡ä»¶")
        sys.exit(1)

    latest_file = max(result_files, key=lambda p: p.stat().st_mtime)
    print(f"ğŸ“‚ åŠ è½½ç»“æœæ–‡ä»¶: {latest_file.name}\n")

    with open(latest_file, 'r', encoding='utf-8') as f:
        return json.load(f)


def print_v3_comparison(results: List[Dict]):
    """æ‰“å°v3ç‰ˆæœ¬çš„å¯¹æ¯”åˆ†æ"""

    print("=" * 120)
    print(" " * 45 + "å®éªŒ3 v3 æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print(" " * 40 + "(LLMè¯„åˆ† + æµå¼è¾“å‡º + å»¶è¿Ÿæ¨¡æ‹Ÿ)")
    print("=" * 120)

    # æ”¶é›†æ•°æ®
    m1_data = {"eval": [], "timing": [], "metrics": []}
    m2_data = {"eval": [], "timing": [], "metrics": []}
    m3_data = {"eval": [], "timing": [], "metrics": []}
    m4_data = {"eval": [], "timing": [], "metrics": []}

    for result in results:
        if "method1_baseline" in result:
            m1_data["eval"].append(result["method1_baseline"]["evaluation"])
            m1_data["timing"].append(result["method1_baseline"]["timing"])
            m1_data["metrics"].append(result["method1_baseline"]["metrics"])

        if "method2_batch" in result:
            m2_data["eval"].append(result["method2_batch"]["evaluation"])
            m2_data["timing"].append(result["method2_batch"]["timing"])
            m2_data["metrics"].append(result["method2_batch"]["metrics"])

        if "method3_incremental" in result:
            m3_data["eval"].append(result["method3_incremental"]["evaluation"])
            m3_data["timing"].append(result["method3_incremental"]["timing"])
            m3_data["metrics"].append(result["method3_incremental"]["metrics"])

        if "method4_incremental_rag" in result:
            m4_data["eval"].append(result["method4_incremental_rag"]["evaluation"])
            m4_data["timing"].append(result["method4_incremental_rag"]["timing"])
            m4_data["metrics"].append(result["method4_incremental_rag"]["metrics"])

    # 1. LLMè¯„åˆ†å¯¹æ¯”
    print("\nã€1. LLMç»¼åˆè¯„åˆ†ã€‘ï¼ˆ0-100åˆ†ï¼‰")
    print("-" * 150)
    print(f"{'è¯„ä¼°ç»´åº¦':<20} {'M1:Baseline':<25} {'M2:Batch':<25} {'M3:Incr-v2':<25} {'M4:Incr-RAG-v3':<25}")
    print("-" * 150)

    # è®¡ç®—å„é¡¹å¹³å‡åˆ†
    metrics_names = [
        ("ä¿¡æ¯ä¿ç•™ç‡", "info_retention_score"),
        ("å™ªéŸ³è¿‡æ»¤ç‡", "noise_filtering_score"),
        ("RAGç›¸å…³æ€§", "rag_relevance_score"),
        ("å›å¤è´¨é‡", "response_quality_score"),
        ("ç®€æ´åº¦", "conciseness_score"),
        ("æ€»åˆ†", "total_score")
    ]

    for name, key in metrics_names:
        m1_avg = statistics.mean([e[key] for e in m1_data["eval"] if key in e]) if m1_data["eval"] else 0
        m2_avg = statistics.mean([e[key] for e in m2_data["eval"] if key in e]) if m2_data["eval"] else 0
        m3_avg = statistics.mean([e[key] for e in m3_data["eval"] if key in e]) if m3_data["eval"] else 0
        m4_avg = statistics.mean([e[key] for e in m4_data["eval"] if key in e]) if m4_data["eval"] else 0

        print(f"{name:<20} {m1_avg:<25.1f} {m2_avg:<25.1f} {m3_avg:<25.1f} {m4_avg:<25.1f}")

    # 2. å»¶è¿Ÿåˆ†æ
    print("\nã€2. å»¶è¿Ÿåˆ†æã€‘ï¼ˆç§’ï¼‰")
    print("-" * 150)
    print(f"{'å»¶è¿ŸæŒ‡æ ‡':<20} {'M1:Baseline':<25} {'M2:Batch':<25} {'M3:Incr-v2':<25} {'M4:Incr-RAG-v3':<25}")
    print("-" * 150)

    # RAGæ£€ç´¢æ—¶é—´
    m1_rag = statistics.mean([t["rag_time"] for t in m1_data["timing"]]) if m1_data["timing"] else 0
    m2_rag = statistics.mean([t["rag_time"] for t in m2_data["timing"]]) if m2_data["timing"] else 0
    m3_rag = statistics.mean([t["rag_time"] for t in m3_data["timing"]]) if m3_data["timing"] else 0
    m4_rag = statistics.mean([t["rag_time"] for t in m4_data["timing"]]) if m4_data["timing"] else 0
    print(f"{'RAGæ£€ç´¢æ—¶é—´':<20} {m1_rag:<25.2f} {m2_rag:<25.2f} {m3_rag:<25.2f} {m4_rag:<25.2f}")

    # é¦–tokenå»¶è¿Ÿ (TTFT)
    m1_ttft = statistics.mean([t["ttft"] for t in m1_data["timing"]]) if m1_data["timing"] else 0
    m2_ttft = statistics.mean([t["ttft"] for t in m2_data["timing"]]) if m2_data["timing"] else 0
    m3_ttft = statistics.mean([t["ttft"] for t in m3_data["timing"]]) if m3_data["timing"] else 0
    m4_ttft = statistics.mean([t["ttft"] for t in m4_data["timing"]]) if m4_data["timing"] else 0
    print(f"{'é¦–tokenå»¶è¿Ÿ(TTFT)':<20} {m1_ttft:<25.2f} {m2_ttft:<25.2f} {m3_ttft:<25.2f} {m4_ttft:<25.2f}")

    # ç”Ÿæˆæ—¶é—´
    m1_gen = statistics.mean([t["generation_time"] for t in m1_data["timing"]]) if m1_data["timing"] else 0
    m2_gen = statistics.mean([t["generation_time"] for t in m2_data["timing"]]) if m2_data["timing"] else 0
    m3_gen = statistics.mean([t["generation_time"] for t in m3_data["timing"]]) if m3_data["timing"] else 0
    m4_gen = statistics.mean([t["generation_time"] for t in m4_data["timing"]]) if m4_data["timing"] else 0
    print(f"{'ç”Ÿæˆæ—¶é—´':<20} {m1_gen:<25.2f} {m2_gen:<25.2f} {m3_gen:<25.2f} {m4_gen:<25.2f}")

    # æ€»å»¶è¿Ÿï¼ˆè¾“å…¥å®Œæˆåï¼‰
    m1_total = statistics.mean([t["total_time"] for t in m1_data["timing"]]) if m1_data["timing"] else 0
    m2_total = statistics.mean([t["total_time"] for t in m2_data["timing"]]) if m2_data["timing"] else 0
    m3_total = statistics.mean([t.get("total_time_after_input", t.get("total_time", 0)) for t in m3_data["timing"]]) if m3_data["timing"] else 0
    m4_total = statistics.mean([t.get("total_time_after_input", t.get("total_time", 0)) for t in m4_data["timing"]]) if m4_data["timing"] else 0
    print(f"{'æ€»å»¶è¿Ÿ(è¾“å…¥å)':<20} {m1_total:<25.2f} {m2_total:<25.2f} {m3_total:<25.2f} {m4_total:<25.2f}")

    # æ–¹æ³•3/4ç‰¹æœ‰ï¼šæ€»ç»“å¤„ç†æ—¶é—´
    if m3_data["timing"]:
        m3_summary = statistics.mean([t.get("summary_processing_time", 0) for t in m3_data["timing"]])
        m4_summary = statistics.mean([t.get("summary_processing_time", 0) for t in m4_data["timing"]]) if m4_data["timing"] else 0
        print(f"{'æ€»ç»“å¤„ç†æ—¶é—´':<20} {'-':<25} {'-':<25} {m3_summary:<25.2f} {m4_summary:<25.2f}")

    # 3. è¾“å‡ºè´¨é‡
    print("\nã€3. è¾“å‡ºè´¨é‡ã€‘")
    print("-" * 150)
    print(f"{'è´¨é‡æŒ‡æ ‡':<20} {'M1:Baseline':<25} {'M2:Batch':<25} {'M3:Incr-v2':<25} {'M4:Incr-RAG-v3':<25}")
    print("-" * 150)

    # Queryé•¿åº¦
    m1_qlen = statistics.mean([m["query_length"] for m in m1_data["metrics"]]) if m1_data["metrics"] else 0
    m2_qlen = statistics.mean([m["query_length"] for m in m2_data["metrics"]]) if m2_data["metrics"] else 0
    m3_qlen = statistics.mean([m["query_length"] for m in m3_data["metrics"]]) if m3_data["metrics"] else 0
    m4_qlen = statistics.mean([m["query_length"] for m in m4_data["metrics"]]) if m4_data["metrics"] else 0
    print(f"{'Queryé•¿åº¦(å­—)':<20} {m1_qlen:<25.0f} {m2_qlen:<25.0f} {m3_qlen:<25.0f} {m4_qlen:<25.0f}")

    # å‹ç¼©æ¯”
    m2_comp = statistics.mean([m.get("compression_ratio", 0) for m in m2_data["metrics"]]) if m2_data["metrics"] else 0
    m3_comp = statistics.mean([m.get("compression_ratio", 0) for m in m3_data["metrics"]]) if m3_data["metrics"] else 0
    m4_comp = statistics.mean([m.get("compression_ratio", 0) for m in m4_data["metrics"]]) if m4_data["metrics"] else 0
    print(f"{'å‹ç¼©æ¯”':<20} {'-':<25} {f'{m2_comp:.1%}':<25} {f'{m3_comp:.1%}':<25} {f'{m4_comp:.1%}':<25}")

    # Tokenè¾“å‡ºé€Ÿåº¦
    m1_tps = statistics.mean([m.get("tokens_per_second", 0) for m in m1_data["metrics"]]) if m1_data["metrics"] else 0
    m2_tps = statistics.mean([m.get("tokens_per_second", 0) for m in m2_data["metrics"]]) if m2_data["metrics"] else 0
    m3_tps = statistics.mean([m.get("tokens_per_second", 0) for m in m3_data["metrics"]]) if m3_data["metrics"] else 0
    m4_tps = statistics.mean([m.get("tokens_per_second", 0) for m in m4_data["metrics"]]) if m4_data["metrics"] else 0
    print(f"{'è¾“å‡ºé€Ÿåº¦(tok/s)':<20} {m1_tps:<25.1f} {m2_tps:<25.1f} {m3_tps:<25.1f} {m4_tps:<25.1f}")

    # æ–¹æ³•4ç‰¹æœ‰ï¼šæ£€ç´¢æ–‡æ¡£æ•°é‡
    if m4_data["metrics"]:
        m4_docs = statistics.mean([m.get("total_relevant_docs", 0) for m in m4_data["metrics"]])
        print(f"{'æ£€ç´¢æ–‡æ¡£æ•°':<20} {'-':<25} {'-':<25} {'-':<25} {m4_docs:<25.1f}")

    print("\n" + "=" * 150)

    # 4. å…³é”®å‘ç°
    print("\nğŸ“Š å…³é”®å‘ç°")
    print("=" * 150)

    print("\n1ï¸âƒ£ ç»¼åˆè¯„åˆ†å¯¹æ¯”:")
    m1_score = statistics.mean([e["total_score"] for e in m1_data["eval"]]) if m1_data["eval"] else 0
    m2_score = statistics.mean([e["total_score"] for e in m2_data["eval"]]) if m2_data["eval"] else 0
    m3_score = statistics.mean([e["total_score"] for e in m3_data["eval"]]) if m3_data["eval"] else 0
    m4_score = statistics.mean([e["total_score"] for e in m4_data["eval"]]) if m4_data["eval"] else 0

    print(f"   - æ–¹æ³•1 (Baseline): {m1_score:.1f}/100")
    print(f"   - æ–¹æ³•2 (Batch Summary): {m2_score:.1f}/100")
    print(f"   - æ–¹æ³•3 (Incremental v2): {m3_score:.1f}/100")
    print(f"   - æ–¹æ³•4 (Incremental RAG v3): {m4_score:.1f}/100")

    best = max(m1_score, m2_score, m3_score, m4_score)
    if best == m4_score:
        print("   âœ… æ¸è¿›å¼æ€»ç»“+å¢é‡RAG (v3) ç»¼åˆè¯„åˆ†æœ€é«˜")
    elif best == m3_score:
        print("   âœ… æ¸è¿›å¼æ€»ç»“ (v2) ç»¼åˆè¯„åˆ†æœ€é«˜")
    elif best == m2_score:
        print("   âœ… æ‰¹é‡æ€»ç»“ç»¼åˆè¯„åˆ†æœ€é«˜")
    else:
        print("   âœ… Baselineç»¼åˆè¯„åˆ†æœ€é«˜")

    print("\n2ï¸âƒ£ ç”¨æˆ·ä½“éªŒï¼ˆè¾“å…¥å®Œæˆåç­‰å¾…æ—¶é—´ï¼‰:")
    print(f"   - æ–¹æ³•1: {m1_total:.2f}ç§’")
    print(f"   - æ–¹æ³•2: {m2_total:.2f}ç§’")
    print(f"   - æ–¹æ³•3: {m3_total:.2f}ç§’")
    print(f"   - æ–¹æ³•4: {m4_total:.2f}ç§’")

    fastest = min(m1_total, m2_total, m3_total, m4_total)
    if fastest == m4_total:
        print("   âœ… æ¸è¿›å¼æ€»ç»“+å¢é‡RAG (v3) ç­‰å¾…æ—¶é—´æœ€çŸ­")
    elif fastest == m3_total:
        print("   âœ… æ¸è¿›å¼æ€»ç»“ (v2) ç­‰å¾…æ—¶é—´æœ€çŸ­")
    elif fastest == m2_total:
        print("   âœ… æ‰¹é‡æ€»ç»“ç­‰å¾…æ—¶é—´æœ€çŸ­")
    else:
        print("   âœ… Baselineç­‰å¾…æ—¶é—´æœ€çŸ­")

    print("\n3ï¸âƒ£ é¦–tokenå»¶è¿Ÿ (TTFT):")
    print(f"   - æ–¹æ³•1: {m1_ttft:.2f}ç§’")
    print(f"   - æ–¹æ³•2: {m2_ttft:.2f}ç§’")
    print(f"   - æ–¹æ³•3: {m3_ttft:.2f}ç§’")
    print(f"   - æ–¹æ³•4: {m4_ttft:.2f}ç§’")

    print("\n4ï¸âƒ£ Queryå‹ç¼©æ•ˆæœ:")
    print(f"   - æ–¹æ³•1: {m1_qlen:.0f}å­—ï¼ˆæ— å‹ç¼©ï¼‰")
    print(f"   - æ–¹æ³•2: {m2_qlen:.0f}å­—ï¼ˆå‹ç¼©è‡³{m2_comp:.1%}ï¼‰")
    print(f"   - æ–¹æ³•3: {m3_qlen:.0f}å­—ï¼ˆå‹ç¼©è‡³{m3_comp:.1%}ï¼‰")
    print(f"   - æ–¹æ³•4: {m4_qlen:.0f}å­—ï¼ˆå‹ç¼©è‡³{m4_comp:.1%}ï¼‰")

    best_comp = min([c for c in [m2_comp, m3_comp, m4_comp] if c > 0])
    if best_comp == m4_comp and m4_comp > 0:
        print("   âœ… æ¸è¿›å¼æ€»ç»“+å¢é‡RAG (v3) å‹ç¼©æ•ˆæœæœ€å¥½")
    elif best_comp == m3_comp and m3_comp > 0:
        print("   âœ… æ¸è¿›å¼æ€»ç»“ (v2) å‹ç¼©æ•ˆæœæœ€å¥½")
    elif best_comp == m2_comp and m2_comp > 0:
        print("   âœ… æ‰¹é‡æ€»ç»“å‹ç¼©æ•ˆæœæœ€å¥½")

    print("\n5ï¸âƒ£ æ–¹æ³•4 (v3) çš„ç‰¹ç‚¹:")
    if m4_data["timing"]:
        avg_summary_time = statistics.mean([t.get("summary_processing_time", 0) for t in m4_data["timing"]])
        avg_docs = statistics.mean([m.get("total_relevant_docs", 0) for m in m4_data["metrics"]]) if m4_data["metrics"] else 0
        print(f"   - æ€»ç»“å¤„ç†æ—¶é—´: {avg_summary_time:.2f}ç§’ï¼ˆåœ¨ç”¨æˆ·è¯´è¯æ—¶å®Œæˆï¼‰")
        print(f"   - å¢é‡RAGæ—¶é—´: {m4_rag:.2f}ç§’ï¼ˆåˆ†æ•£åœ¨å„æ®µï¼‰")
        print(f"   - å¹³å‡æ£€ç´¢æ–‡æ¡£æ•°: {avg_docs:.1f}ä¸ªï¼ˆå»é‡+è¿‡æ»¤åï¼‰")
        print(f"   - ç”¨æˆ·æ„ŸçŸ¥å»¶è¿Ÿ: {m4_total:.2f}ç§’ï¼ˆä»…æœ€ç»ˆç”Ÿæˆæ—¶é—´ï¼‰")
        print(f"   âœ… æ€»ç»“å’ŒRAGéƒ½åœ¨ç”¨æˆ·è¾“å…¥è¿‡ç¨‹ä¸­å®Œæˆï¼Œæœ€å¤§åŒ–é™ä½å»¶è¿Ÿ")

    print("\n6ï¸âƒ£ æ¸è¿›å¼æ€»ç»“çš„ä¼˜åŠ¿:")
    if m3_data["timing"] or m4_data["timing"]:
        print(f"   - æ€»ç»“æ—¶é—´éšè—åœ¨ç”¨æˆ·è¾“å…¥è¿‡ç¨‹ä¸­")
        print(f"   - ç”¨æˆ·è¾“å…¥å®Œæˆåï¼Œåªéœ€ç­‰å¾…ç”Ÿæˆæ—¶é—´")
        print(f"   - ç›¸æ¯”æ‰¹é‡æ€»ç»“ï¼Œç”¨æˆ·æ„ŸçŸ¥å»¶è¿Ÿæ˜¾è‘—é™ä½")
        if m4_data["timing"]:
            print(f"   - v3ç‰ˆæœ¬çš„å¢é‡RAGè¿›ä¸€æ­¥æå‡äº†æ£€ç´¢è´¨é‡å’Œä¿¡æ¯ä¿ç•™ç‡")

    print("\n" + "=" * 150)
    print("\nğŸ’¡ ç»“è®º:")
    print("   - æ¸è¿›å¼æ€»ç»“å°†å¤„ç†æ—¶é—´åˆ†æ•£åˆ°ç”¨æˆ·è¾“å…¥è¿‡ç¨‹ä¸­")
    print("   - v3ç‰ˆæœ¬é€šè¿‡å¢é‡RAGå’Œç›¸å…³åº¦è¿‡æ»¤ï¼Œåœ¨ä¿æŒä½å»¶è¿Ÿçš„åŒæ—¶æå‡äº†å›å¤è´¨é‡")
    print("   - æ€»ç»“è¾“å…¥åŒ…å«å®Œæ•´æ®µè½æ–‡æœ¬ï¼Œé¿å…äº†v2ç‰ˆæœ¬çš„ä¿¡æ¯ä¸¢å¤±é—®é¢˜")
    print("   - LLMè¯„åˆ†æ˜¾ç¤ºæ¸è¿›å¼æ–¹æ³•åœ¨å„é¡¹æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜ç§€")
    print("\n" + "=" * 150)


def main():
    results = load_latest_v3_results()
    print(f"âœ… æˆåŠŸåŠ è½½ {len(results)} ä¸ªæµ‹è¯•ç”¨ä¾‹çš„ç»“æœ\n")
    print_v3_comparison(results)


if __name__ == "__main__":
    main()
