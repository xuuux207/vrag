"""
RAG å®ç”¨å·¥å…·åº“

ä½¿ç”¨åœ¨çº¿ Embeddingï¼ˆBAAI/bge-m3ï¼‰å’Œ Rerankingï¼ˆBAAI/bge-reranker-v2-m3ï¼‰
å®Œæ•´çš„ Embedding â†’ Indexing â†’ Retrieval â†’ Reranking æµç¨‹
"""

import os
import re
import time
import json
import pickle
import numpy as np
import requests
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# ============================================================================
# ç¬¬ 1 éƒ¨åˆ†ï¼šEmbedding æœåŠ¡
# ============================================================================

class EmbeddingService:
    """åœ¨çº¿ Embedding æœåŠ¡ï¼ˆä½¿ç”¨ BAAI/bge-m3ï¼‰"""
    
    def __init__(self):
        self.model = os.getenv("EMBEDDING_MODEL", "BAAI/bge-m3")
        self.url = os.getenv("EMBEDDING_URL", "https://api.siliconflow.cn/v1/embeddings")
        self.token = os.getenv("EMBEDDING_TOKEN")
        
        if not self.token:
            raise ValueError("âŒ ç¼ºå°‘ EMBEDDING_TOKENï¼Œè¯·åœ¨ .env ä¸­é…ç½®")
        
        self.headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }
        self.dimension = 768  # BGE-M3 è¾“å‡ºç»´åº¦
    
    def embed_texts(self, texts: List[str]) -> List[List[float]]:
        """
        æ‰¹é‡åµŒå…¥æ–‡æœ¬
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
        
        Returns:
            å‘é‡åˆ—è¡¨ï¼Œæ¯ä¸ªå‘é‡æ˜¯ 768 ç»´
        
        ç¤ºä¾‹ï¼š
            >>> service = EmbeddingService()
            >>> embeddings = service.embed_texts(["æ–‡æœ¬1", "æ–‡æœ¬2"])
            >>> len(embeddings)  # 2
            >>> len(embeddings[0])  # 768
        """
        if not texts:
            return []
        
        payload = {
            "model": self.model,
            "input": texts,
            "encoding_format": "float"
        }
        
        try:
            response = requests.post(self.url, json=payload, headers=self.headers, timeout=30)
            response.raise_for_status()
            result = response.json()
            
            # æå–å‘é‡
            embeddings = []
            for item in result.get("data", []):
                embeddings.append(item["embedding"])
            
            if len(embeddings) != len(texts):
                raise ValueError(f"è¿”å›çš„å‘é‡æ•° ({len(embeddings)}) != è¾“å…¥æ–‡æœ¬æ•° ({len(texts)})")
            
            return embeddings
        
        except requests.exceptions.RequestException as e:
            raise RuntimeError(f"âŒ Embedding API è°ƒç”¨å¤±è´¥: {e}")
    
    def embed_single(self, text: str) -> List[float]:
        """åµŒå…¥å•ä¸ªæ–‡æœ¬"""
        return self.embed_texts([text])[0]


# ============================================================================
# ç¬¬ 2 éƒ¨åˆ†ï¼šå‘é‡ç´¢å¼•
# ============================================================================

class VectorIndex:
    """
    å‘é‡ç´¢å¼•ï¼ˆæ”¯æŒæœ¬åœ°æŒä¹…åŒ–ï¼‰
    
    å­˜å‚¨æ–¹å¼ï¼š
    - å†…å­˜ï¼šPython dictï¼ˆå¿«é€Ÿè®¿é—®ï¼‰
    - æŒä¹…åŒ–ï¼špickle æ–‡ä»¶ï¼ˆä¿å­˜/åŠ è½½ï¼‰
    
    åŠŸèƒ½ï¼š
    - æ–‡æ¡£å‘é‡å­˜å‚¨
    - æ–‡æ¡£å…ƒä¿¡æ¯ç®¡ç†
    - ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
    - ä»æœ¬åœ°æ–‡ä»¶åŠ è½½
    - å¢é‡æ›´æ–°ï¼ˆé¿å…é‡å¤åµŒå…¥ï¼‰
    """
    
    def __init__(self, embedding_service: EmbeddingService, cache_dir: str = "./vector_cache"):
        self.embedding_service = embedding_service
        self.documents = {}  # doc_id -> {title, content}
        self.vectors = {}    # doc_id -> np.array
        self.dimension = embedding_service.dimension
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def add_documents(self, documents: List[Dict]) -> None:
        """
        æ·»åŠ æ–‡æ¡£å¹¶ç”Ÿæˆå‘é‡
        
        Args:
            documents: [
                {
                    "id": "doc_1",
                    "title": "æ ‡é¢˜",
                    "content": "å†…å®¹"
                },
                ...
            ]
        
        è¿”å›ï¼šNoneï¼ˆä¿®æ”¹å†…éƒ¨çŠ¶æ€ï¼‰
        """
        if not documents:
            print("âš ï¸  æ²¡æœ‰æ–‡æ¡£è¦æ·»åŠ ")
            return
        
        # æå–å†…å®¹ç”¨äºåµŒå…¥
        doc_contents = []
        doc_ids = []
        
        for doc in documents:
            doc_ids.append(doc["id"])
            # ç»„åˆæ ‡é¢˜å’Œå†…å®¹ä½œä¸ºåµŒå…¥å¯¹è±¡
            title = doc.get("title", "")
            content = doc.get("content", "")
            combined = f"{title} {content}".strip()
            doc_contents.append(combined)
        
        print(f"ğŸ“Š æ­£åœ¨åµŒå…¥ {len(doc_contents)} ä¸ªæ–‡æ¡£...")
        start_time = time.time()
        
        # æ‰¹é‡è°ƒç”¨ API
        embeddings = self.embedding_service.embed_texts(doc_contents)
        
        elapsed = time.time() - start_time
        print(f"âœ“ Embedding å®Œæˆ (è€—æ—¶ {elapsed:.2f}s)")
        
        # å­˜å‚¨
        for doc_id, doc, embedding in zip(doc_ids, documents, embeddings):
            self.documents[doc_id] = {
                "title": doc.get("title", ""),
                "content": doc.get("content", "")
            }
            self.vectors[doc_id] = np.array(embedding)
        
        print(f"âœ“ æˆåŠŸç´¢å¼• {len(self.vectors)} ä¸ªæ–‡æ¡£")
    
    def add_document_incremental(self, doc_id: str, title: str, content: str) -> bool:
        """
        å¢é‡æ·»åŠ å•ä¸ªæ–‡æ¡£ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™è·³è¿‡ï¼‰
        
        Args:
            doc_id: æ–‡æ¡£ ID
            title: æ–‡æ¡£æ ‡é¢˜
            content: æ–‡æ¡£å†…å®¹
        
        Returns:
            True: æ–°å¢æˆåŠŸï¼ŒFalse: å·²å­˜åœ¨è·³è¿‡
        """
        if doc_id in self.documents:
            print(f"â­ï¸  æ–‡æ¡£ {doc_id} å·²å­˜åœ¨ï¼Œè·³è¿‡")
            return False
        
        # åµŒå…¥å•ä¸ªæ–‡æ¡£
        combined = f"{title} {content}".strip()
        embedding = self.embedding_service.embed_single(combined)
        
        # å­˜å‚¨
        self.documents[doc_id] = {"title": title, "content": content}
        self.vectors[doc_id] = np.array(embedding)
        
        print(f"âœ“ æ–°å¢æ–‡æ¡£ {doc_id}")
        return True
    
    def save(self, filename: str = "vector_index.pkl") -> None:
        """
        ä¿å­˜ç´¢å¼•åˆ°æœ¬åœ°æ–‡ä»¶
        
        Args:
            filename: ä¿å­˜çš„æ–‡ä»¶å
        """
        filepath = self.cache_dir / filename
        
        data = {
            "documents": self.documents,
            "vectors": {doc_id: vec.tolist() for doc_id, vec in self.vectors.items()},
            "dimension": self.dimension
        }
        
        with open(filepath, "wb") as f:
            pickle.dump(data, f)
        
        print(f"ğŸ’¾ ç´¢å¼•å·²ä¿å­˜åˆ° {filepath} ({len(self.documents)} ä¸ªæ–‡æ¡£)")
    
    def load(self, filename: str = "vector_index.pkl") -> bool:
        """
        ä»æœ¬åœ°æ–‡ä»¶åŠ è½½ç´¢å¼•
        
        Args:
            filename: åŠ è½½çš„æ–‡ä»¶å
        
        Returns:
            True: åŠ è½½æˆåŠŸï¼ŒFalse: æ–‡ä»¶ä¸å­˜åœ¨
        """
        filepath = self.cache_dir / filename
        
        if not filepath.exists():
            print(f"âš ï¸  ç´¢å¼•æ–‡ä»¶ {filepath} ä¸å­˜åœ¨")
            return False
        
        with open(filepath, "rb") as f:
            data = pickle.load(f)
        
        self.documents = data["documents"]
        self.vectors = {doc_id: np.array(vec) for doc_id, vec in data["vectors"].items()}
        self.dimension = data["dimension"]
        
        print(f"ğŸ“‚ ç´¢å¼•å·²åŠ è½½ {filepath} ({len(self.documents)} ä¸ªæ–‡æ¡£)")
        return True
    
    def clear(self) -> None:
        """æ¸…ç©ºç´¢å¼•"""
        self.documents.clear()
        self.vectors.clear()
        print("ğŸ—‘ï¸  ç´¢å¼•å·²æ¸…ç©º")
    
    def get_vector(self, doc_id: str) -> Optional[np.ndarray]:
        """è·å–æ–‡æ¡£å‘é‡"""
        return self.vectors.get(doc_id)
    
    def get_all_vectors(self) -> Tuple[List[str], np.ndarray]:
        """
        è·å–æ‰€æœ‰å‘é‡
        
        Returns:
            (doc_ids, vectors_matrix)
            vectors_matrix çš„å½¢çŠ¶ä¸º (num_docs, 768)
        """
        doc_ids = list(self.vectors.keys())
        vectors = np.array([self.vectors[doc_id] for doc_id in doc_ids])
        return doc_ids, vectors
    
    def size(self) -> int:
        """ç´¢å¼•ä¸­çš„æ–‡æ¡£æ•°"""
        return len(self.vectors)


# ============================================================================
# ç¬¬ 3 éƒ¨åˆ†ï¼šæ£€ç´¢å‡½æ•°
# ============================================================================

def retrieve_by_similarity(query: str,
                          embedding_service: EmbeddingService,
                          index: VectorIndex,
                          top_k: int = 10) -> List[Dict]:
    """
    ç›¸ä¼¼åº¦æ£€ç´¢
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        embedding_service: EmbeddingService å®ä¾‹
        index: VectorIndex å®ä¾‹
        top_k: è¿”å›å‰ k ä¸ªç»“æœ
    
    Returns:
        [
            {
                "doc_id": "...",
                "similarity": 0.856,
                "title": "...",
                "content": "..."
            },
            ...
        ]
    """
    # åµŒå…¥æŸ¥è¯¢
    query_embedding = embedding_service.embed_single(query)
    query_vector = np.array(query_embedding)
    
    # è·å–æ‰€æœ‰å‘é‡
    doc_ids, all_vectors = index.get_all_vectors()
    
    if len(doc_ids) == 0:
        print("âš ï¸  ç´¢å¼•ä¸­æ²¡æœ‰æ–‡æ¡£")
        return []
    
    # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
    similarities = []
    
    for doc_id, doc_vector in zip(doc_ids, all_vectors):
        # ä½™å¼¦ç›¸ä¼¼åº¦ = dot(a, b) / (norm(a) * norm(b))
        # å› ä¸ºå‘é‡å·²é€šå¸¸è¢« embedding æ¨¡å‹å½’ä¸€åŒ–ï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥ä½¿ç”¨ dot ä½œä¸ºç›¸ä¼¼åº¦
        similarity = np.dot(query_vector, doc_vector)
        
        similarities.append({
            "doc_id": doc_id,
            "similarity": float(similarity),
            "title": index.documents[doc_id]["title"],
            "content": index.documents[doc_id]["content"]
        })
    
    # æ’åºå¹¶è¿”å› Top-K
    similarities = sorted(similarities, key=lambda x: x["similarity"], reverse=True)
    return similarities[:top_k]


# ============================================================================
# ç¬¬ 4 éƒ¨åˆ†ï¼šReranking æœåŠ¡
# ============================================================================

class RerankingService:
    """åœ¨çº¿ Reranking æœåŠ¡ï¼ˆä½¿ç”¨ BAAI/bge-reranker-v2-m3ï¼‰"""
    
    def __init__(self):
        self.model = os.getenv("RERANKING_MODEL", "BAAI/bge-reranker-v2-m3")
        self.url = os.getenv("RERANKING_URL", "https://api.siliconflow.cn/v1/rerankings")
        self.token = os.getenv("RERANKING_TOKEN")
        
        if not self.token:
            raise ValueError("âŒ ç¼ºå°‘ RERANKING_TOKENï¼Œè¯·åœ¨ .env ä¸­é…ç½®")
        
        self.headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }
    
    def rerank(self, query: str, passages: List[Dict], top_k: int = 3) -> List[Dict]:
        """
        Reranking ç²¾æ’
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            passages: [{"doc_id": "...", "title": "...", "content": "...", "similarity": 0.8}, ...]
            top_k: è¿”å›å‰ k ä¸ªç»“æœ
        
        Returns:
            é‡æ’åçš„ passagesï¼ˆåŒæ ·çš„ç»“æ„ï¼Œä½†åŠ ä¸Š rerank_scoreï¼‰
        """
        if not passages:
            return []
        
        # æå–å†…å®¹åˆ—è¡¨
        contents = [p["content"] for p in passages]
        
        payload = {
            "model": self.model,
            "query": query,
            "passages": contents,
            "top_n": min(top_k, len(passages))
        }
        
        try:
            response = requests.post(self.url, json=payload, headers=self.headers, timeout=30)
            response.raise_for_status()
            result = response.json()
            
            # æå–é‡æ’åçš„ç»“æœ
            reranked = []
            for item in result.get("results", []):
                idx = item["index"]
                score = item["score"]
                
                reranked.append({
                    **passages[idx],
                    "rerank_score": float(score)
                })
            
            return reranked[:top_k]
        
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸  Reranking å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹é¡ºåº")
            return passages[:top_k]


# ============================================================================
# ç¬¬ 5 éƒ¨åˆ†ï¼šå®Œæ•´ RAG æµç¨‹
# ============================================================================

def rag_retrieve_and_rerank(query: str,
                           embedding_service: EmbeddingService,
                           reranking_service: RerankingService,
                           index: VectorIndex,
                           retrieval_top_k: int = 10,
                           rerank_top_k: int = 3,
                           verbose: bool = True) -> Tuple[List[Dict], List[Dict]]:
    """
    å®Œæ•´ RAG æµç¨‹ï¼šEmbedding â†’ Retrieval â†’ Reranking
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        embedding_service: EmbeddingService å®ä¾‹
        reranking_service: RerankingService å®ä¾‹
        index: VectorIndex å®ä¾‹
        retrieval_top_k: æ£€ç´¢é˜¶æ®µè¿”å›å¤šå°‘ä¸ªå€™é€‰
        rerank_top_k: Reranking åè¿”å›å¤šå°‘ä¸ªç»“æœ
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        (final_results, retrieval_results)
        - final_results: æœ€ç»ˆçš„ reranked ç»“æœ
        - retrieval_results: åŸå§‹æ£€ç´¢ç»“æœï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    """
    if verbose:
        print("\n" + "="*70)
        print(f"ã€RAG æµç¨‹ã€‘æŸ¥è¯¢: {query[:60]}")
        print("="*70)
    
    start_time = time.time()
    
    # ç¬¬ 1 æ­¥ï¼šç›¸ä¼¼åº¦æ£€ç´¢
    if verbose:
        print("\n[æ­¥éª¤ 1] ç›¸ä¼¼åº¦æ£€ç´¢...")
    
    retrieval_results = retrieve_by_similarity(
        query, embedding_service, index, top_k=retrieval_top_k
    )
    
    if verbose:
        print(f"âœ“ æ£€ç´¢åˆ° {len(retrieval_results)} ä¸ªå€™é€‰æ–‡æ¡£")
        for i, r in enumerate(retrieval_results[:3], 1):
            print(f"  {i}. {r['title']} (ç›¸ä¼¼åº¦: {r['similarity']:.3f})")
    
    # ç¬¬ 2 æ­¥ï¼šReranking ç²¾æ’
    if verbose:
        print("\n[æ­¥éª¤ 2] Reranking ç²¾æ’åº...")
    
    final_results = reranking_service.rerank(
        query, retrieval_results, top_k=rerank_top_k
    )
    
    if verbose:
        print(f"âœ“ ç²¾æ’å Top {len(final_results)} ä¸ªç»“æœï¼š")
        for i, r in enumerate(final_results, 1):
            score = r.get("rerank_score", r.get("similarity"))
            print(f"  {i}. {r['title']} (åˆ†æ•°: {score:.3f})")
    
    elapsed = time.time() - start_time
    if verbose:
        print(f"\nâ±ï¸  æ€»è€—æ—¶: {elapsed:.2f}s")
    
    return final_results, retrieval_results


def build_rag_context(rag_results: List[Dict]) -> str:
    """
    ä» RAG ç»“æœç»„ç»‡èƒŒæ™¯çŸ¥è¯†ä¸Šä¸‹æ–‡
    
    Args:
        rag_results: RAG è¿”å›çš„ç»“æœåˆ—è¡¨
    
    Returns:
        æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼Œå¯ç›´æ¥ç”¨äº LLM æç¤ºè¯
    """
    if not rag_results:
        return ""
    
    context = "ã€æ£€ç´¢åˆ°çš„èƒŒæ™¯çŸ¥è¯†ã€‘\n\n"
    
    for i, result in enumerate(rag_results, 1):
        context += f"{i}. {result['title']}\n"
        context += f"   {result['content'][:300]}...\n\n"
    
    return context


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def extract_keywords(text: str, num_keywords: int = 5) -> List[str]:
    """
    ç®€å•å…³é”®è¯æå–
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        num_keywords: è¿”å›å…³é”®è¯æ•°é‡
    
    Returns:
        å…³é”®è¯åˆ—è¡¨
    """
    # ç®€å•å®ç°ï¼šæŒ‰é•¿åº¦è¿‡æ»¤
    words = re.findall(r'[\w\u4e00-\u9fff]+', text)
    stopwords = {
        'çš„', 'æ˜¯', 'åœ¨', 'äº†', 'å’Œ', 'ä¸', 'æˆ–', 'ç­‰', 'æˆ‘', 'ä»¬', 'æ‚¨',
        'æœ‰', 'èƒ½', 'å¯ä»¥', 'è¿›è¡Œ', 'å®ç°', 'ä¸º', 'è¢«', 'æ¥', 'åˆ°', 'ä»'
    }
    keywords = [w for w in words if w not in stopwords and len(w) > 1]
    return keywords[:num_keywords]


if __name__ == "__main__":
    print("âœ“ RAG å·¥å…·åº“åŠ è½½æˆåŠŸ")
    print("  - EmbeddingService")
    print("  - VectorIndex")
    print("  - RerankingService")
    print("  - æ£€ç´¢å’Œ Reranking å‡½æ•°")
