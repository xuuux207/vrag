"""
Speech-to-Text æœåŠ¡ï¼ˆSilero VAD + Azure STTï¼‰
ä½¿ç”¨å®˜æ–¹silero-vadåº“è¿›è¡Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ŒAzure Speech SDKè¿›è¡Œè¯†åˆ«
"""

import logging
import threading
from typing import Callable, Optional
import numpy as np
import torch
import pyaudio
import azure.cognitiveservices.speech as speechsdk
from silero_vad import load_silero_vad

logger = logging.getLogger(__name__)


class STTSileroService:
    """è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼ˆSilero VAD + Azure STTï¼‰"""

    def __init__(
        self,
        key: str,
        region: str,
        language: str = "zh-CN",
        sample_rate: int = 16000,
        vad_threshold: float = 0.5,
        model_path: str = None,
        min_speech_duration: float = 0.3,
        min_silence_duration: float = 1.0,
    ):
        """
        åˆå§‹åŒ–STTæœåŠ¡

        Args:
            key: Azure Speech APIå¯†é’¥
            region: AzureåŒºåŸŸ
            language: è¯†åˆ«è¯­è¨€ï¼ˆé»˜è®¤zh-CNï¼‰
            sample_rate: é‡‡æ ·ç‡ï¼ˆé»˜è®¤16000Hzï¼‰
            vad_threshold: VADé˜ˆå€¼ï¼ˆ0-1ï¼Œé»˜è®¤0.5ï¼‰
            model_path: ä¿ç•™å‚æ•°ï¼Œå…¼å®¹æ€§ç”¨ï¼ˆå®˜æ–¹åº“è‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼‰
            min_speech_duration: æœ€å°è¯­éŸ³æ—¶é•¿ï¼ˆç§’ï¼Œé»˜è®¤0.3ï¼‰
            min_silence_duration: æœ€å°é™éŸ³æ—¶é•¿ï¼ˆç§’ï¼Œé»˜è®¤1.0ï¼Œåœé¡¿å¤šä¹…ç®—ç»“æŸï¼‰
        """
        self.key = key
        self.region = region
        self.language = language
        self.sample_rate = sample_rate
        self.vad_threshold = vad_threshold
        self.vad_sample_rate = 16000  # Silero VADå›ºå®š16kHz
        self.chunk_size = 512  # æ¯æ¬¡å¤„ç†çš„å¸§æ•°
        self.audio_gain = 50.0  # éŸ³é¢‘å¢ç›Šå€æ•°ï¼ˆæé«˜éº¦å…‹é£çµæ•åº¦ï¼‰

        # åˆå§‹åŒ–Silero VADï¼ˆå®˜æ–¹åº“ï¼‰
        self._init_silero_vad()

        # VADçŠ¶æ€
        self.min_speech_frames = int(min_speech_duration * sample_rate / self.chunk_size)
        self.min_silence_frames = int(min_silence_duration * sample_rate / self.chunk_size)
        self.is_speech = False
        self.speech_counter = 0
        self.silence_counter = 0

        # AGCï¼ˆè‡ªåŠ¨å¢ç›Šæ§åˆ¶ï¼‰å‚æ•°
        self.agc_enabled = True  # å¯ç”¨AGC
        self.agc_target_rms = 0.15  # ç›®æ ‡RMSï¼ˆ15%ç”µå¹³ï¼‰
        self.agc_history_size = 100  # å†å²çª—å£å¤§å°ï¼ˆå¸§æ•°ï¼‰
        self.agc_rms_history = []  # RMSå†å²è®°å½•
        self.agc_current_gain = 1.0  # å½“å‰å¢ç›Šç³»æ•°
        self.agc_max_gain = 50.0  # æœ€å¤§å¢ç›Š
        self.agc_min_gain = 1.0  # æœ€å°å¢ç›Š
        self.agc_adaptation_rate = 0.05  # å¢ç›Šè°ƒæ•´é€Ÿç‡

        # PyAudio
        self.audio = pyaudio.PyAudio()
        self.stream = None

        # è¯†åˆ«å™¨
        self.recognizer = None
        self._is_recognizing = False
        self._stop_event = threading.Event()

        # å›è°ƒ
        self.on_recognizing = None
        self.on_recognized = None
        self.on_session_started = None
        self.on_session_stopped = None
        self.on_canceled = None
        self.on_speech_started = None  # VADæ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹çš„å›è°ƒï¼ˆç”¨äºæ‰“æ–­æ£€æµ‹ï¼‰

    def _init_silero_vad(self):
        """åˆå§‹åŒ–Silero VADï¼ˆå®˜æ–¹åº“ï¼‰"""
        try:
            logger.info("åŠ è½½Silero VADæ¨¡å‹ï¼ˆå®˜æ–¹åº“ï¼‰...")
            self.vad_model = load_silero_vad()
            logger.info("âœ“ Silero VADæ¨¡å‹åŠ è½½å®Œæˆ")
        except Exception as e:
            logger.error(f"åŠ è½½Silero VADæ¨¡å‹å¤±è´¥: {str(e)}")
            raise

    def start_continuous_recognition(
        self,
        on_recognizing: Callable[[str], None],
        on_recognized: Callable[[str], None],
        on_session_started: Optional[Callable[[], None]] = None,
        on_session_stopped: Optional[Callable[[], None]] = None,
        on_canceled: Optional[Callable[[str], None]] = None,
        on_speech_started: Optional[Callable[[], None]] = None,
    ):
        """
        å¯åŠ¨è¿ç»­è¯†åˆ«ï¼ˆSilero VAD + Azure STTï¼‰

        Args:
            on_recognizing: éƒ¨åˆ†è¯†åˆ«ç»“æœå›è°ƒ
            on_recognized: æœ€ç»ˆè¯†åˆ«ç»“æœå›è°ƒ
            on_session_started: ä¼šè¯å¼€å§‹å›è°ƒ
            on_session_stopped: ä¼šè¯åœæ­¢å›è°ƒ
            on_canceled: å–æ¶ˆ/é”™è¯¯å›è°ƒ
            on_speech_started: VADæ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹å›è°ƒï¼ˆç”¨äºæ‰“æ–­æ£€æµ‹ï¼‰
        """
        if self._is_recognizing:
            logger.warning("è¯†åˆ«å·²åœ¨è¿è¡Œä¸­")
            return

        self.on_recognizing = on_recognizing
        self.on_recognized = on_recognized
        self.on_session_started = on_session_started
        self.on_session_stopped = on_session_stopped
        self.on_canceled = on_canceled
        self.on_speech_started = on_speech_started

        try:
            # é…ç½®Azure Speech
            speech_config = speechsdk.SpeechConfig(
                subscription=self.key, region=self.region
            )
            speech_config.speech_recognition_language = self.language

            # ä½¿ç”¨PushAudioInputStreamï¼ˆä»Silero VADè¾“å‡ºï¼‰
            self.push_stream = speechsdk.audio.PushAudioInputStream()
            audio_config = speechsdk.audio.AudioConfig(stream=self.push_stream)

            self.recognizer = speechsdk.SpeechRecognizer(
                speech_config=speech_config, audio_config=audio_config
            )

            # ç»‘å®šAzure STTäº‹ä»¶
            self.recognizer.recognizing.connect(self._on_recognizing_event)
            self.recognizer.recognized.connect(self._on_recognized_event)
            self.recognizer.session_started.connect(self._on_session_started_event)
            self.recognizer.session_stopped.connect(self._on_session_stopped_event)
            self.recognizer.canceled.connect(self._on_canceled_event)

            # å¯åŠ¨Azureè¯†åˆ«å™¨
            self.recognizer.start_continuous_recognition()
            self._is_recognizing = True
            logger.info("Silero VAD + Azure STT å·²å¯åŠ¨")

            # å¯åŠ¨Silero VADéŸ³é¢‘é‡‡é›†çº¿ç¨‹
            self._stop_event.clear()
            self._vad_thread = threading.Thread(target=self._vad_loop, daemon=True)
            self._vad_thread.start()

            if self.on_session_started:
                self.on_session_started()

        except Exception as e:
            logger.error(f"å¯åŠ¨å¤±è´¥: {str(e)}")
            self._is_recognizing = False
            if self.on_canceled:
                self.on_canceled(f"å¯åŠ¨å¤±è´¥: {str(e)}")
            raise

    def _vad_loop(self):
        """Silero VADéŸ³é¢‘é‡‡é›†ä¸»å¾ªç¯"""
        try:
            # æ‰“å¼€éº¦å…‹é£æµ
            self.stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size,
            )

            logger.info("Silero VAD éŸ³é¢‘é‡‡é›†å·²å¯åŠ¨")

            speech_buffer = []

            frame_count = 0
            while not self._stop_event.is_set():
                # è¯»å–éŸ³é¢‘å¸§
                audio_chunk = self.stream.read(self.chunk_size, exception_on_overflow=False)
                audio_int16 = np.frombuffer(audio_chunk, dtype=np.int16)

                # è®¡ç®—éŸ³é¢‘ç”µå¹³ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                amplitude = np.abs(audio_int16).mean()
                amplitude_pct = (amplitude / 32768.0) * 100

                # Silero VADæ£€æµ‹
                speech_prob = self._process_vad_chunk(audio_int16)
                is_speech_frame = speech_prob > self.vad_threshold

                # å®æ—¶æ˜¾ç¤ºï¼ˆæ¯10å¸§ï¼ŒDEBUGçº§åˆ«ï¼‰
                frame_count += 1
                if frame_count % 10 == 0:
                    status = "ğŸ—£ï¸ è¯­éŸ³" if is_speech_frame else "  é™éŸ³"
                    logger.debug(f"[å®æ—¶] ç”µå¹³:{amplitude_pct:4.1f}% VAD:{speech_prob:.4f} {status}")

                if is_speech_frame:
                    # æ£€æµ‹åˆ°è¯­éŸ³
                    speech_buffer.append(audio_chunk)
                    self.speech_counter += 1
                    self.silence_counter = 0

                    if not self.is_speech and self.speech_counter >= self.min_speech_frames:
                        self.is_speech = True
                        logger.info(f"[VAD] è¯­éŸ³å¼€å§‹ (prob={speech_prob:.4f}, counter={self.speech_counter})")
                        # è§¦å‘è¯­éŸ³å¼€å§‹å›è°ƒï¼ˆç”¨äºæ‰“æ–­æ£€æµ‹ï¼‰
                        if self.on_speech_started:
                            self.on_speech_started()
                else:
                    # é™éŸ³
                    self.silence_counter += 1
                    self.speech_counter = 0

                    if self.is_speech:
                        speech_buffer.append(audio_chunk)

                        if self.silence_counter >= self.min_silence_frames:
                            # è¯­éŸ³ç»“æŸï¼Œæ¨é€åˆ°Azure STT
                            if speech_buffer:
                                full_audio = b"".join(speech_buffer)
                                self.push_stream.write(full_audio)
                                logger.info(f"[VAD] è¯­éŸ³ç»“æŸï¼Œæ¨é€ {len(speech_buffer)} å¸§ ({len(full_audio)} bytes) åˆ°Azure STT")

                            speech_buffer = []
                            self.is_speech = False
                            logger.info("[VAD] ç­‰å¾…ä¸‹ä¸€æ®µè¯­éŸ³...")

            # å…³é—­æµ
            if self.stream:
                self.stream.stop_stream()
                self.stream.close()
                logger.info("Silero VAD éŸ³é¢‘é‡‡é›†å·²åœæ­¢")

        except Exception as e:
            logger.error(f"VADå¾ªç¯é”™è¯¯: {str(e)}")
            if self.on_canceled:
                self.on_canceled(f"VADé”™è¯¯: {str(e)}")

    def _process_vad_chunk(self, audio_data: np.ndarray) -> float:
        """
        å¤„ç†éŸ³é¢‘å—ï¼Œè¿”å›è¯­éŸ³æ¦‚ç‡ï¼ˆå¸¦AGCè‡ªåŠ¨å¢ç›Šæ§åˆ¶ï¼‰

        Args:
            audio_data: int16éŸ³é¢‘æ•°æ®

        Returns:
            è¯­éŸ³æ¦‚ç‡ï¼ˆ0-1ï¼‰
        """
        try:
            # è½¬æ¢ä¸ºfloat32å¹¶å½’ä¸€åŒ–
            audio_float32 = audio_data.astype(np.float32) / 32768.0

            # è®¡ç®—åŸå§‹RMS
            original_rms = np.sqrt(np.mean(audio_float32 ** 2))

            # AGCè‡ªåŠ¨å¢ç›Šæ§åˆ¶
            if self.agc_enabled and original_rms > 0.0001:
                # æ›´æ–°RMSå†å²
                self.agc_rms_history.append(original_rms)
                if len(self.agc_rms_history) > self.agc_history_size:
                    self.agc_rms_history.pop(0)

                # è®¡ç®—å†å²å¹³å‡RMSï¼ˆç”¨äºç¨³å®šå¢ç›Šè°ƒæ•´ï¼‰
                if len(self.agc_rms_history) >= 10:  # è‡³å°‘10å¸§åæ‰å¼€å§‹è°ƒæ•´
                    avg_rms = np.mean(self.agc_rms_history[-50:])  # ä½¿ç”¨æœ€è¿‘50å¸§

                    # è®¡ç®—ç†æƒ³å¢ç›Š
                    ideal_gain = self.agc_target_rms / avg_rms if avg_rms > 0.0001 else self.agc_min_gain
                    ideal_gain = np.clip(ideal_gain, self.agc_min_gain, self.agc_max_gain)

                    # å¹³æ»‘è°ƒæ•´å½“å‰å¢ç›Šï¼ˆé¿å…çªå˜ï¼‰
                    self.agc_current_gain += (ideal_gain - self.agc_current_gain) * self.agc_adaptation_rate
                    self.agc_current_gain = np.clip(self.agc_current_gain, self.agc_min_gain, self.agc_max_gain)

                # åº”ç”¨å¢ç›Š
                audio_float32 = audio_float32 * self.agc_current_gain

                # è½¯é™å¹…ï¼ˆé˜²æ­¢å‰Šæ³¢ï¼‰
                audio_float32 = np.tanh(audio_float32)

                # è®°å½•å¢ç›Šåçš„RMS
                gained_rms = np.sqrt(np.mean(audio_float32 ** 2))

                # æ¯100å¸§æ‰“å°ä¸€æ¬¡AGCçŠ¶æ€ï¼ˆDEBUGçº§åˆ«ï¼‰
                if not hasattr(self, '_vad_frame_count'):
                    self._vad_frame_count = 0
                self._vad_frame_count += 1

                if self._vad_frame_count % 100 == 0:
                    logger.debug(f"[AGC] åŸå§‹RMS:{original_rms:.4f} å¢ç›Š:{self.agc_current_gain:.1f}x è¾“å‡ºRMS:{gained_rms:.4f}")
            else:
                # AGCæœªå¯ç”¨æˆ–ä¿¡å·å¤ªå¼±ï¼Œä½¿ç”¨å›ºå®šå¢ç›Š
                audio_float32 = audio_float32 * self.audio_gain
                audio_float32 = np.tanh(audio_float32)

            # è½¬æ¢ä¸ºtorch tensorå¹¶æ¨ç†ï¼ˆå®˜æ–¹åº“ï¼‰
            audio_tensor = torch.from_numpy(audio_float32)

            with torch.no_grad():
                speech_prob = self.vad_model(audio_tensor, self.vad_sample_rate).item()

            return speech_prob

        except Exception as e:
            logger.error(f"VADå¤„ç†é”™è¯¯: {str(e)}")
            return 0.0

    def stop_continuous_recognition(self):
        """åœæ­¢è¿ç»­è¯†åˆ«"""
        if not self._is_recognizing:
            return

        try:
            # åœæ­¢VADçº¿ç¨‹
            self._stop_event.set()
            if self._vad_thread:
                self._vad_thread.join(timeout=2.0)

            # åœæ­¢Azureè¯†åˆ«å™¨
            if self.recognizer:
                self.recognizer.stop_continuous_recognition()

            self._is_recognizing = False
            logger.info("å·²åœæ­¢è¿ç»­è¯­éŸ³è¯†åˆ«")

        except Exception as e:
            logger.error(f"åœæ­¢è¯†åˆ«å¤±è´¥: {str(e)}")

    def _on_recognizing_event(self, evt):
        """Azure STTéƒ¨åˆ†è¯†åˆ«äº‹ä»¶"""
        if evt.result.reason == speechsdk.ResultReason.RecognizingSpeech:
            text = evt.result.text
            if text.strip() and self.on_recognizing:
                self.on_recognizing(text)

    def _on_recognized_event(self, evt):
        """Azure STTæœ€ç»ˆè¯†åˆ«äº‹ä»¶"""
        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
            text = evt.result.text
            if text.strip() and self.on_recognized:
                self.on_recognized(text)
        elif evt.result.reason == speechsdk.ResultReason.NoMatch:
            logger.debug("æœªè¯†åˆ«åˆ°è¯­éŸ³")

    def _on_session_started_event(self, evt):
        """ä¼šè¯å¯åŠ¨äº‹ä»¶"""
        logger.info("Azure STT ä¼šè¯å·²å¯åŠ¨")

    def _on_session_stopped_event(self, evt):
        """ä¼šè¯åœæ­¢äº‹ä»¶"""
        self._is_recognizing = False
        logger.info("Azure STT ä¼šè¯å·²åœæ­¢")
        if self.on_session_stopped:
            self.on_session_stopped()

    def _on_canceled_event(self, evt):
        """å–æ¶ˆäº‹ä»¶"""
        self._is_recognizing = False
        reason = f"è¯†åˆ«å–æ¶ˆ: {evt.result.cancellation_details.reason}"
        if evt.result.cancellation_details.reason == speechsdk.CancellationReason.Error:
            error_details = evt.result.cancellation_details.error_details
            reason = f"è¯†åˆ«é”™è¯¯: {error_details}"
            logger.error(reason)
        if self.on_canceled:
            self.on_canceled(reason)

    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if self.audio:
            self.audio.terminate()
