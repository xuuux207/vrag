{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è™šæ‹Ÿé”€å”®ç³»ç»Ÿ Workshopï¼šå®æ—¶æ€§ä¸ä¸“ä¸šæ€§çš„å·¥ç¨‹è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "## æ ¸å¿ƒç›®æ ‡\n",
    "\n",
    "è§£å†³è™šæ‹Ÿé”€å”®/å®¢æœç³»ç»Ÿä¸­çš„**ä¸‰ä¸ªç‹¬ç«‹å·¥ç¨‹é—®é¢˜**ï¼š\n",
    "\n",
    "- **â‰¤1500ms ç«¯åˆ°ç«¯å»¶è¿Ÿ** - ä¿è¯å®æ—¶äº¤äº’ä½“éªŒ\n",
    "- **30è½®å†…æ— æ˜¾è‘—å¹»è§‰çš„ä¸“ä¸šå¯¹è¯** - ç¡®ä¿å›ç­”å‡†ç¡®å¯é \n",
    "- **40-60ç§’é•¿è¯­éŸ³çš„å‡†ç¡®ç†è§£** - å®Œæ•´æ•æ‰å®¢æˆ·éœ€æ±‚\n",
    "\n",
    "---\n",
    "\n",
    "## Workshop ç»“æ„\n",
    "\n",
    "```\n",
    "å¯¼å…¥éƒ¨åˆ† (æ€»)\n",
    "    â†“\n",
    "Block 1: æ¨¡å‹é€‰å‹ä¸å»¶è¿Ÿåˆ†æ\n",
    "    â†“\n",
    "Block 2: RAG å¼‚æ„æ•°æ®èåˆ\n",
    "    â†“\n",
    "Block 3: é•¿è¾“å…¥å¤„ç†\n",
    "    â†“\n",
    "å®Œæ•´ Pipeline æ¼”ç¤º\n",
    "    â†“\n",
    "æ€»ç»“ä¸è®¨è®º (æ€»)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ä¸ºä»€ä¹ˆä¸è®² MoEï¼Ÿ\n",
    "\n",
    "### è¯¯åŒºæ¾„æ¸…\n",
    "\n",
    "åŸå§‹éœ€æ±‚æåˆ°ï¼šLLM ä¸“ä¸šåº¦æå‡æ–¹æ¡ˆï¼Œä½¿ç”¨ MoE è·¯ç”±æ¶æ„ï¼ˆæŒ‰è¡Œä¸šæˆ–äº§å“ç±»å‹åˆ’åˆ†ï¼‰\n",
    "\n",
    "**ä½†å®é™…ä¸Š**ï¼š\n",
    "- âŒ **è¯¯åŒº1**ï¼šä¸éœ€è¦è‡ªå·±è®­ç»ƒ MoE æ¨¡å‹â€”â€”Qwen ç­‰æ¨¡å‹å·²å†…ç½®å¤šä¸“å®¶æœºåˆ¶\n",
    "- âŒ **è¯¯åŒº2**ï¼šMoE è·¯ç”±**ä¸èƒ½æ ¹æœ¬è§£å†³å¹»è§‰é—®é¢˜**â€”â€”å¹»è§‰æºäºçŸ¥è¯†ä¸è¶³ï¼Œè€Œéæ¨¡å‹é€‰æ‹©\n",
    "- âœ… **æ­£ç¡®ç†è§£**ï¼šåŸºç¡€æ¨¡å‹ + é«˜è´¨é‡çŸ¥è¯†åº“ + å·¥ç¨‹ä¼˜åŒ– = æ ¸å¿ƒè§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "### æœ¬ Workshop çš„è§†è§’\n",
    "\n",
    "æˆ‘ä»¬å…³æ³¨çš„æ˜¯**å·¥ç¨‹è®¾è®¡è€Œéæ¨¡å‹é»‘ç›’**ï¼š\n",
    "1. **æ¨¡å‹é€‰æ‹©æ˜¯æ‰‹æ®µ**ï¼šé€‰åˆé€‚è§„æ¨¡çš„ Qwenï¼Œç¡®ä¿å»¶è¿Ÿå¯æ§\n",
    "2. **çŸ¥è¯†åº“æ˜¯å…³é”®**ï¼šç”¨ RAG ä»å¼‚æ„æ•°æ®ç²¾å‡†æ£€ç´¢ï¼Œé˜²æ­¢å¹»è§‰\n",
    "3. **å¤„ç†æµç¨‹æ˜¯ä¿éšœ**ï¼šé•¿è¾“å…¥åˆ†æ®µã€å®Œæ•´ç†è§£ï¼Œç¡®ä¿å›ç­”å‡†ç¡®\n",
    "\n",
    "**MoE çš„çœŸå®ä½ç½®**ï¼šå¦‚æœä¸Šè¿°ä¸‰ä¸ªç¯èŠ‚éƒ½ä¼˜åŒ–åï¼Œç³»ç»Ÿä»å­˜åœ¨ä¸“ä¸šåº¦ä¸è¶³çš„é—®é¢˜ï¼Œ**é‚£æ—¶**æ‰è€ƒè™‘ MoE ä½œä¸ºåç»­ä¼˜åŒ–ã€‚ä½†ç»å¤§å¤šæ•°åœºæ™¯ä¸‹ï¼Œè¿™ä¸‰ä¸ªç¯èŠ‚å°±å·²ç»è¶³å¤Ÿäº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 0: ç¯å¢ƒåˆå§‹åŒ–\n",
    "\n",
    "### æ£€æŸ¥ vLLM æœåŠ¡\n",
    "\n",
    "æœ¬ Workshop ä½¿ç”¨æœ¬åœ° vLLM æœåŠ¡ï¼š\n",
    "- **Qwen3-8B** @ localhost:8000 (è½»é‡çº§ä»»åŠ¡)\n",
    "- **Qwen3-14B** @ localhost:8001 (ä¸»å¯¹è¯ç”Ÿæˆ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥ vLLM æœåŠ¡æ˜¯å¦è¿è¡Œ\n",
    "import requests\n",
    "\n",
    "def check_vllm_service(port, model_name):\n",
    "    \"\"\"æ£€æŸ¥ vLLM æœåŠ¡çŠ¶æ€\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"http://localhost:{port}/v1/models\", timeout=3)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"âœ“ {model_name} æœåŠ¡è¿è¡Œæ­£å¸¸ (ç«¯å£ {port})\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âœ— {model_name} æœåŠ¡å¼‚å¸¸ (ç«¯å£ {port}): {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âœ— {model_name} æœåŠ¡æœªè¿è¡Œ (ç«¯å£ {port})\")\n",
    "        return False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"æ£€æŸ¥ vLLM æœåŠ¡çŠ¶æ€\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "service_8b = check_vllm_service(8000, \"Qwen3-8B\")\n",
    "service_14b = check_vllm_service(8001, \"Qwen3-14B\")\n",
    "\n",
    "if not service_8b or not service_14b:\n",
    "    print(\"\\nâš ï¸  vLLM æœåŠ¡æœªå®Œå…¨å¯åŠ¨\")\n",
    "    print(\"   â†’ è¯·è¿è¡Œä¸‹é¢çš„ bash cell å¯åŠ¨æœåŠ¡\")\n",
    "else:\n",
    "    print(\"\\nâœ“ æ‰€æœ‰æœåŠ¡è¿è¡Œæ­£å¸¸ï¼Œå¯ä»¥è·³è¿‡ä¸‹é¢çš„å¯åŠ¨æ­¥éª¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (å¯é€‰) æ£€æŸ¥GPUçŠ¶æ€\n",
    "\n",
    "å¦‚æœéœ€è¦å¯åŠ¨vLLMï¼Œå…ˆæ£€æŸ¥GPUæ˜¯å¦å¯ç”¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# æ£€æŸ¥GPUçŠ¶æ€\n",
    "nvidia-smi --query-gpu=index,name,memory.total,memory.used,memory.free --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯åŠ¨ vLLM æœåŠ¡ï¼ˆå¦‚æœæœªè¿è¡Œï¼‰\n",
    "\n",
    "**æ³¨æ„**ï¼šè¿™ä¸ªcellä¼šåœ¨åå°å¯åŠ¨vLLMæœåŠ¡ï¼Œå¤§çº¦éœ€è¦1-2åˆ†é’ŸåŠ è½½æ¨¡å‹ã€‚\n",
    "\n",
    "å¯åŠ¨åè¯·ç­‰å¾…çº¦1-2åˆ†é’Ÿï¼Œç„¶åé‡æ–°è¿è¡Œä¸Šé¢çš„æ£€æŸ¥cellç¡®è®¤æœåŠ¡å·²å¯åŠ¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "# åå°å¯åŠ¨vLLMåŒæ¨¡å‹æœåŠ¡\n",
    "bash scripts/start_dual_vllm_services.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯¼å…¥æ ¸å¿ƒåº“\n",
    "\n",
    "å¯¼å…¥é¡¹ç›®æ‰€éœ€çš„æ ¸å¿ƒåº“ï¼ˆOpenAIå®¢æˆ·ç«¯ã€RAGç»„ä»¶ã€çŸ¥è¯†åº“æ•°æ®ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥æ ¸å¿ƒåº“\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from openai import OpenAI\n",
    "from rag_utils import (\n",
    "    EmbeddingService, RerankingService, VectorIndex,\n",
    "    BM25, hybrid_search, build_rag_context\n",
    ")\n",
    "from data.fictional_knowledge_base import FICTIONAL_DOCUMENTS\n",
    "from data.company_graph import convert_all_companies_to_documents\n",
    "\n",
    "print(\"âœ“ æ ¸å¿ƒåº“å¯¼å…¥æˆåŠŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆå§‹åŒ– RAG æœåŠ¡\n",
    "\n",
    "è¿™ä¸€æ­¥ä¼šåˆå§‹åŒ–æ‰€æœ‰å¿…è¦çš„æœåŠ¡ç»„ä»¶ï¼ˆvLLMå®¢æˆ·ç«¯ã€Embeddingã€Rerankingã€å‘é‡ç´¢å¼•ã€BM25ç´¢å¼•ï¼‰ã€‚\n",
    "\n",
    "**æ³¨æ„**ï¼šè¿™ä¸€æ­¥è€—æ—¶è¾ƒé•¿ï¼ˆçº¦30-60ç§’ï¼‰ï¼Œå› ä¸ºéœ€è¦ï¼š\n",
    "- è¿æ¥vLLMæœåŠ¡\n",
    "- åŠ è½½54ä¸ªçŸ¥è¯†åº“æ–‡æ¡£\n",
    "- æ„å»ºå‘é‡ç´¢å¼•ï¼ˆè°ƒç”¨Embedding APIï¼‰\n",
    "- æ„å»ºBM25ç´¢å¼•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–æœåŠ¡\n",
    "print(\"åˆå§‹åŒ– RAG æœåŠ¡...\")\n",
    "\n",
    "# åˆ›å»º vLLM å®¢æˆ·ç«¯\n",
    "client_8b = OpenAI(api_key=\"EMPTY\", base_url=\"http://localhost:8000/v1\")\n",
    "client_14b = OpenAI(api_key=\"EMPTY\", base_url=\"http://localhost:8001/v1\")\n",
    "print(\"âœ“ vLLM å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ\")\n",
    "\n",
    "# åˆå§‹åŒ– RAG ç»„ä»¶\n",
    "embedding_svc = EmbeddingService()\n",
    "reranking_svc = RerankingService()\n",
    "vector_idx = VectorIndex(embedding_svc)\n",
    "print(\"âœ“ RAG ç»„ä»¶åˆå§‹åŒ–å®Œæˆ\")\n",
    "\n",
    "# åŠ è½½çŸ¥è¯†åº“\n",
    "all_docs = FICTIONAL_DOCUMENTS + convert_all_companies_to_documents()\n",
    "print(f\"âœ“ åŠ è½½çŸ¥è¯†åº“: {len(FICTIONAL_DOCUMENTS)} ä¸ªä¸šåŠ¡æ–‡æ¡£ + {len(convert_all_companies_to_documents())} ä¸ªå…¬å¸æ–‡æ¡£\")\n",
    "\n",
    "# æ„å»ºå‘é‡ç´¢å¼•\n",
    "vector_idx.add_documents(all_docs)\n",
    "print(f\"âœ“ å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ: å…± {len(all_docs)} ä¸ªæ–‡æ¡£\")\n",
    "\n",
    "# æ„å»º BM25 ç´¢å¼•\n",
    "corpus = [f\"{doc['title']} {doc['content']}\" for doc in all_docs]\n",
    "bm25_idx = BM25(corpus)\n",
    "print(\"âœ“ BM25 ç´¢å¼•æ„å»ºå®Œæˆ\")\n",
    "\n",
    "print(\"\\n=\" * 60)\n",
    "print(\"æ‰€æœ‰æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œå‡†å¤‡å¼€å§‹å®éªŒ\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Block 1 - æ¨¡å‹é€‰å‹ä¸å»¶è¿Ÿåˆ†æ\n",
    "\n",
    "### é—®é¢˜\n",
    "åº”è¯¥é€‰å¤šå¤§çš„ Qwen æ¨¡å‹æ‰èƒ½æ»¡è¶³ â‰¤500ms æ¨ç†æ—¶é—´ï¼Ÿ\n",
    "\n",
    "### å› æœé“¾\n",
    "500ms æ¨ç†çº¦æŸ â†’ æ¨¡å‹è§„æ¨¡ â†’ ç¡¬ä»¶éœ€æ±‚\n",
    "\n",
    "### è§£å†³æ€è·¯\n",
    "1. **Qwen ç³»åˆ—å¯¹æ ‡**: 3B/7B/14B/72B å‚æ•°è§„æ¨¡é€‰æ‹©\n",
    "2. **æ¨ç†é€Ÿåº¦è®¡ç®—**: å• token ç”Ÿæˆæ—¶é—´ Ã— å¹³å‡å›ç­”é•¿åº¦ = æ¨ç†å»¶è¿Ÿ\n",
    "3. **å®éªŒéªŒè¯**: åœ¨ç›®æ ‡ç¡¬ä»¶ä¸Šè·‘ benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç†è®ºå»¶è¿Ÿä¼°ç®—\n",
    "\n",
    "é€šè¿‡ç®€å•è®¡ç®—è¯„ä¼°ä¸åŒå‚æ•°è§„æ¨¡æ¨¡å‹çš„æ¨ç†å»¶è¿Ÿï¼ˆç†è®ºå€¼ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç†è®ºå»¶è¿Ÿä¼°ç®—\n",
    "import numpy as np\n",
    "\n",
    "models = {\n",
    "    \"Qwen3-3B\": {\"params\": 3e9, \"tokens_per_sec\": 100},\n",
    "    \"Qwen3-7B\": {\"params\": 7e9, \"tokens_per_sec\": 50},\n",
    "    \"Qwen3-14B\": {\"params\": 14e9, \"tokens_per_sec\": 25},\n",
    "    \"Qwen3-72B\": {\"params\": 72e9, \"tokens_per_sec\": 8},\n",
    "}\n",
    "\n",
    "avg_response_tokens = 50  # å¹³å‡å›ç­”é•¿åº¦\n",
    "\n",
    "print(\"æ¨ç†å»¶è¿Ÿä¼°ç®— (å‡è®¾å¹³å‡å›ç­”50ä¸ªtoken):\")\n",
    "print(\"-\" * 50)\n",
    "for name, spec in models.items():\n",
    "    inference_time = avg_response_tokens / spec[\"tokens_per_sec\"]\n",
    "    status = \"âœ“ å¯è¡Œ\" if inference_time <= 1.5 else \"âœ— è¶…é™\"\n",
    "    print(f\"{name}: {inference_time:.3f}s {status}\")\n",
    "\n",
    "print(\"\\næ³¨æ„: è¿™æ˜¯ç†è®ºä¼°ç®—ï¼Œå®é™…æµ‹è¯•ç»“æœè§ä¸‹æ–‡å®éªŒ1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®éªŒ1ç»“æœï¼šæ¨¡å‹å¯¹æ¯”æµ‹è¯•\n",
    "\n",
    "**å®éªŒæ—¶é—´**: 2024-12-13  \n",
    "**æµ‹è¯•ä»£ç **: `experiments/test_01_model_comparison.py`  \n",
    "**æ•°æ®æ–‡ä»¶**: `outputs/experiment1_results_llm_scored_200059.json`  \n",
    "\n",
    "#### æµ‹è¯•æ¨¡å‹ä¸æ€§èƒ½\n",
    "\n",
    "| æ¨¡å‹ | å‡†ç¡®æ€§ | å®Œæ•´æ€§ | å¹³å‡å»¶è¿Ÿ(s) | é€Ÿåº¦(tok/s) | è¯„ä»· |\n",
    "|------|--------|--------|-------------|-------------|------|\n",
    "| qwen3-8b | 6.7/10 | 7.7/10 | 21.77 | 4.4 | âŒ é€Ÿåº¦æœ€æ…¢ï¼Œä¸é€‚åˆå®æ—¶ |\n",
    "| **qwen3-14b** | 6.7/10 | **7.9/10** | **20.63** | **7.4** | âœ… **æœ€ä½³å¹³è¡¡ç‚¹** |\n",
    "| qwen3-32b | 6.7/10 | 7.8/10 | 35.22 | 9.0 | âš ï¸ é€Ÿåº¦å¿«ä½†åˆå§‹å»¶è¿Ÿé«˜ |\n",
    "\n",
    "#### å…³é”®å‘ç°\n",
    "\n",
    "1. **qwen3-14b æ˜¯å®æ—¶äº¤äº’çš„æœ€ä½³é€‰æ‹©**ï¼šå®Œæ•´æ€§æœ€é«˜ï¼ˆ7.9/10ï¼‰ã€å»¶è¿Ÿæœ€ä½ï¼ˆ20.63ç§’ï¼‰\n",
    "2. **qwen3-8b ä¸é€‚åˆå®æ—¶åœºæ™¯**ï¼šé€Ÿåº¦ä»…4.4 tok/sï¼Œä½†å¯ä½œä¸ºè¾…åŠ©æ¨¡å‹ç”¨äºå¿«é€Ÿåˆ¤æ–­ä»»åŠ¡\n",
    "3. **åŒæ¨¡å‹æ¶æ„**ï¼š8Bï¼ˆRAGåˆ¤æ–­ã€è¾“å…¥å®Œæ•´æ€§æ£€æµ‹ï¼‰+ 14Bï¼ˆä¸»å¯¹è¯ç”Ÿæˆï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½å®éªŒ1ç»“æœ\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "exp1_file = project_root / 'outputs' / 'experiment1_results_llm_scored_200059.json'\n",
    "with open(exp1_file, 'r', encoding='utf-8') as f:\n",
    "    exp1_data = json.load(f)\n",
    "\n",
    "# ç»Ÿè®¡å„æ¨¡å‹æ€§èƒ½\n",
    "models_stats = {}\n",
    "for result in exp1_data['results']:\n",
    "    model = result['model']\n",
    "    if model not in models_stats:\n",
    "        models_stats[model] = {\n",
    "            'accuracy': [],\n",
    "            'completeness': [],\n",
    "            'latency': [],\n",
    "            'speed': []\n",
    "        }\n",
    "    \n",
    "    scores = result['llm_scores']\n",
    "    models_stats[model]['accuracy'].append(scores['accuracy'])\n",
    "    models_stats[model]['completeness'].append(scores['completeness'])\n",
    "    models_stats[model]['latency'].append(result['latency'])\n",
    "    models_stats[model]['speed'].append(result['speed'])\n",
    "\n",
    "# è®¡ç®—å¹³å‡å€¼\n",
    "print(\"å®éªŒ1 - æ¨¡å‹æ€§èƒ½å¯¹æ¯”\")\n",
    "print(\"=\" * 80)\n",
    "for model, stats in models_stats.items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"  å‡†ç¡®æ€§: {np.mean(stats['accuracy']):.1f}/10\")\n",
    "    print(f\"  å®Œæ•´æ€§: {np.mean(stats['completeness']):.1f}/10\")\n",
    "    print(f\"  å¹³å‡å»¶è¿Ÿ: {np.mean(stats['latency']):.2f}s\")\n",
    "    print(f\"  å¹³å‡é€Ÿåº¦: {np.mean(stats['speed']):.1f} tok/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Block 2 - RAG å¼‚æ„æ•°æ®èåˆ\n",
    "\n",
    "### é—®é¢˜\n",
    "ç»“æ„åŒ–ä¼ä¸šå›¾è°±æ•°æ®å’Œéç»“æ„åŒ–ä¸šåŠ¡æ–‡æ¡£æ€ä¹ˆæ•´åˆï¼Œæ‰èƒ½æœ‰æ•ˆé™ä½å¹»è§‰ï¼Ÿ\n",
    "\n",
    "### å› æœé“¾\n",
    "å¼‚æ„æ•°æ®ï¼ˆç»“æ„åŒ–+éç»“æ„åŒ–ï¼‰â†’ åˆ†åˆ«å¤„ç† â†’ ç»Ÿä¸€æ£€ç´¢ â†’ é™ä½å¹»è§‰\n",
    "\n",
    "### è§£å†³æ€è·¯\n",
    "1. **æ•°æ®æºç‰¹å¾åˆ†æ**: ç»“æ„åŒ–ï¼ˆå›¾è°±ï¼‰vs éç»“æ„åŒ–ï¼ˆæ–‡æ¡£ï¼‰\n",
    "2. **åˆ†å¼€å­˜å‚¨çš„ä¼˜åŠ¿**: ç²¾ç¡®æ£€ç´¢ + è¯­ä¹‰æ£€ç´¢\n",
    "3. **èåˆæ£€ç´¢ç­–ç•¥**: BM25 + Dense Vector + RRF + Reranking\n",
    "4. **å¹»è§‰æŠ‘åˆ¶æœºåˆ¶**: æ¥æºæ ‡è®° + è¦†ç›–åº¦è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG å¼‚æ„æ•°æ®èåˆæ¼”ç¤ºï¼ˆç®€åŒ–ç‰ˆï¼‰\n",
    "\n",
    "# 1. ç»“æ„åŒ–æ•°æ®ç¤ºä¾‹ï¼ˆä¼ä¸šå›¾è°±ï¼‰\n",
    "structured_data = {\n",
    "    \"company\": \"è¥¿é—¨å­\",\n",
    "    \"industry\": \"å·¥ä¸šè‡ªåŠ¨åŒ–\",\n",
    "    \"solutions\": [\"PLCæ§åˆ¶\", \"å·¥ä¸šäº’è”ç½‘\", \"æ•°å­—åŒ–è½¬å‹\"],\n",
    "    \"clients\": [\"å®é©¬\", \"å¤§ä¼—\", \"è¥¿é—¨å­ä¸­å›½\"],\n",
    "}\n",
    "\n",
    "# 2. éç»“æ„åŒ–æ•°æ®ç¤ºä¾‹ï¼ˆä¸šåŠ¡æ–‡æ¡£ï¼‰\n",
    "unstructured_docs = [\n",
    "    \"è¥¿é—¨å­ Siemens S7-1200 PLC æ˜¯é¢å‘ä¸­å°å‹åº”ç”¨çš„é«˜æ€§èƒ½æ§åˆ¶å™¨...\",\n",
    "    \"å·¥ä¸š4.0 è§£å†³æ–¹æ¡ˆå¯ä»¥å¸®åŠ©ä¼ ç»Ÿåˆ¶é€ ä¸šå®ç°æ•°å­—åŒ–è½¬å‹...\",\n",
    "    \"äº‘å¹³å°æ”¯æŒå®æ—¶ç›‘æ§å’Œè¿œç¨‹è¯Šæ–­åŠŸèƒ½...\",\n",
    "]\n",
    "\n",
    "# 3. ç”¨æˆ·é—®é¢˜\n",
    "user_query = \"è¥¿é—¨å­çš„ PLC äº§å“æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ\"\n",
    "\n",
    "# 4. åˆ†åˆ«æ£€ç´¢\n",
    "print(\"=== æ£€ç´¢æµç¨‹æ¼”ç¤º ===\\n\")\n",
    "\n",
    "# ç»“æ„åŒ–æ£€ç´¢ï¼ˆç²¾ç¡®ï¼‰\n",
    "print(\"ã€ç»“æ„åŒ–æ£€ç´¢ã€‘\")\n",
    "if \"PLC\" in user_query:\n",
    "    for solution in structured_data[\"solutions\"]:\n",
    "        if \"PLC\" in solution:\n",
    "            print(f\"âœ“ åŒ¹é…: {solution}\")\n",
    "\n",
    "# å‘é‡æ£€ç´¢ï¼ˆæ¨¡æ‹Ÿï¼‰\n",
    "print(\"\\nã€å‘é‡æ£€ç´¢ã€‘\")\n",
    "query_keywords = [\"PLC\", \"ç‰¹ç‚¹\", \"åŠŸèƒ½\"]\n",
    "for i, doc in enumerate(unstructured_docs):\n",
    "    match_score = sum(1 for kw in query_keywords if kw in doc) / len(query_keywords)\n",
    "    if match_score > 0:\n",
    "        print(f\"æ–‡æ¡£ {i+1}: {doc[:50]}... (ç›¸ä¼¼åº¦: {match_score:.2f})\")\n",
    "\n",
    "# 5. èåˆç»“æœ\n",
    "print(\"\\nã€èåˆç»“æœã€‘\")\n",
    "rag_context = f\"\"\"\n",
    "ç»“æ„åŒ–ä¿¡æ¯ï¼šè¥¿é—¨å­çš„æ ¸å¿ƒè§£å†³æ–¹æ¡ˆåŒ…æ‹¬ {', '.join(structured_data['solutions'])}\n",
    "æ–‡æ¡£è¡¥å……ï¼š{unstructured_docs[0][:50]}...\n",
    "\"\"\"\n",
    "print(rag_context)\n",
    "print(\"\\nâ†’ LLM åŸºäºä¸Šè¿°èƒŒæ™¯çŸ¥è¯†å›ç­”ï¼Œé¿å…çº¯ç²¹å¹»è§‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®éªŒ2ç»“æœï¼šæ··åˆRAGç­–ç•¥éªŒè¯\n",
    "\n",
    "**å®éªŒæ—¶é—´**: 2024-12-15 / 2024-12-20  \n",
    "**æµ‹è¯•ä»£ç **: `experiments/test_02_*.py`  \n",
    "\n",
    "#### 4ç§æ£€ç´¢ç­–ç•¥å¯¹æ¯”\n",
    "\n",
    "| æ–¹æ¡ˆ | ç­–ç•¥ | æ£€ç´¢æ—¶é—´ | è¯„ä»· |\n",
    "|------|------|----------|------|\n",
    "| A | Business-only Dense | 934ms | âŒ ä»…ä¸šåŠ¡æ–‡æ¡£ï¼Œç¼ºå°‘å…¬å¸ä¿¡æ¯ |\n",
    "| B | Company-only BM25 | 0.23ms | âš ï¸ ä»…å…¬å¸æ–‡æ¡£ï¼Œç¼ºä¹äº§å“ç»†èŠ‚ |\n",
    "| C | All Dense | 1079ms | âŒ è¯­ä¹‰æ£€ç´¢ï¼Œç²¾ç¡®åŒ¹é…ä¸è¶³ |\n",
    "| **D** | **Hybrid (BM25+Dense+RRF+Rerank)** | 935ms | âœ… **ç»¼åˆæ•ˆæœæœ€ä½³** |\n",
    "\n",
    "#### æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡ï¼ˆæ–¹æ¡ˆD + æœ¬åœ°vLLMï¼‰\n",
    "\n",
    "| æŒ‡æ ‡ | ç»“æœ |\n",
    "|------|------|\n",
    "| **é€šè¿‡ç‡** | **100%** (8/8) âœ… |\n",
    "| **å¹³å‡å¬å›ç‡** | **89.2%** |\n",
    "| å¹³å‡æ£€ç´¢æ—¶é—´ | 1.44ç§’ |\n",
    "| å¹³å‡ç”Ÿæˆæ—¶é—´ | 0.70ç§’ |\n",
    "| **å¹³å‡æ€»å»¶è¿Ÿ** | **2.14ç§’** |\n",
    "\n",
    "#### å…³é”®å‘ç°\n",
    "\n",
    "1. **æ··åˆæ£€ç´¢ç­–ç•¥æ•ˆæœæœ€ä¼˜**: BM25å…³é”®è¯åŒ¹é… + Denseè¯­ä¹‰ç†è§£ + Rerankingç²¾æ’\n",
    "2. **ä¸­æ–‡åˆ†è¯ä¼˜åŒ–æ˜¾è‘—**: è‡ªå®šä¹‰jiebaè¯å…¸ï¼Œå¬å›ç‡ä»70%æå‡è‡³89.2%\n",
    "3. **æœ¬åœ°vLLMé™ä½å»¶è¿Ÿ**: æ€»å»¶è¿Ÿä»…2.14ç§’ï¼Œé€‚åˆå®æ—¶äº¤äº’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çœŸå®æ··åˆæ£€ç´¢æ¼”ç¤º\n",
    "test_query = \"æ˜Ÿè¾°é‡‘èé›†å›¢æƒ³åšå®æ—¶é£æ§ï¼Œåº”è¯¥æ¨èå“ªä¸ªäº§å“ï¼Ÿ\"\n",
    "\n",
    "print(f\"æŸ¥è¯¢: {test_query}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ‰§è¡Œæ··åˆæ£€ç´¢\n",
    "rag_results, debug_info = hybrid_search(\n",
    "    test_query, \n",
    "    bm25_idx, \n",
    "    vector_idx,\n",
    "    embedding_svc, \n",
    "    reranking_svc, \n",
    "    final_top_k=5\n",
    ")\n",
    "\n",
    "print(f\"\\næ£€ç´¢åˆ° {len(rag_results)} ä¸ªç›¸å…³æ–‡æ¡£:\\n\")\n",
    "for i, result in enumerate(rag_results, 1):\n",
    "    print(f\"{i}. [{result['score']:.3f}] {result['title']}\")\n",
    "    print(f\"   {result['content'][:100]}...\\n\")\n",
    "\n",
    "# æ„å»º RAG ä¸Šä¸‹æ–‡\n",
    "context = build_rag_context(rag_results)\n",
    "print(\"\\næ„å»ºçš„RAGä¸Šä¸‹æ–‡:\")\n",
    "print(\"-\" * 60)\n",
    "print(context[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Block 3 - é•¿è¾“å…¥å¤„ç†\n",
    "\n",
    "### é—®é¢˜\n",
    "å®¢æˆ·è®²äº†ä¸€å¤§å †éœ€æ±‚ï¼ˆ40-60ç§’ï¼‰ï¼Œæ€ä¹ˆå¤„ç†æ‰èƒ½æ—¢ä¸ä¸¢å¤±ä¿¡æ¯ï¼Œåˆé¿å…æ¨¡å‹æ··ä¹±å’Œå¹»è§‰ï¼Ÿ\n",
    "\n",
    "### å› æœé“¾\n",
    "40-60ç§’é•¿è¯­éŸ³ â†’ è¯­ä¹‰åˆ†æ®µ â†’ ç‹¬ç«‹ç†è§£ + ä¸Šä¸‹æ–‡ä¿ç•™ â†’ å®Œæ•´å›ç­”\n",
    "\n",
    "### è§£å†³æ€è·¯\n",
    "1. **é•¿è¾“å…¥çš„ä¸¤å¤§æŒ‘æˆ˜**: Token é•¿åº¦è¶…é™ + å¤šéœ€æ±‚æ··åˆ\n",
    "2. **åˆ†æ®µç­–ç•¥**: è¯­ä¹‰è¾¹ç•Œæ£€æµ‹ï¼ˆéå›ºå®šé•¿åº¦æˆªæ–­ï¼‰\n",
    "3. **å¤„ç†æ–¹å¼**: æµå¼ vs èšåˆ vs æ··åˆ\n",
    "4. **è´¨é‡ä¿éšœ**: å…³é”®ç‚¹æå– + æ®µé—´é€»è¾‘ + å®Œæ•´æ€§æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é•¿è¾“å…¥åˆ†æ®µå¤„ç†æ¼”ç¤º\n",
    "import re\n",
    "\n",
    "# æ¨¡æ‹Ÿå®¢æˆ· 60 ç§’çš„è¯­éŸ³è½¬å½•\n",
    "long_input = \"\"\"\n",
    "æˆ‘ä»¬å…¬å¸æ˜¯ä¸€å®¶åˆ¶é€ ä¼ä¸šï¼Œä¸»è¦ç”Ÿäº§æ±½è½¦é›¶éƒ¨ä»¶ã€‚\n",
    "ç›®å‰é¢ä¸´çš„é—®é¢˜æ˜¯ç”Ÿäº§æ•ˆç‡ä½ä¸‹ï¼Œäº§å“ä¸è‰¯ç‡åœ¨ 15% å·¦å³ã€‚\n",
    "æˆ‘ä»¬å¬è¯´è¥¿é—¨å­çš„å·¥ä¸šæ§åˆ¶ç³»ç»Ÿèƒ½å¸®åŠ©ä¼˜åŒ–ç”Ÿäº§æµç¨‹ã€‚\n",
    "å¦å¤–ï¼Œæˆ‘ä»¬çš„åº“å­˜ç®¡ç†ä¹Ÿå¾ˆæ··ä¹±ï¼Œç»å¸¸å‡ºç°è¿‡åº“æˆ–ç¼ºåº“çš„æƒ…å†µã€‚\n",
    "æƒ³é—®ä¸€ä¸‹ï¼Œè¥¿é—¨å­æ˜¯å¦æœ‰å®Œæ•´çš„ ERP åŠ è‡ªåŠ¨åŒ–çš„æ•´ä½“è§£å†³æ–¹æ¡ˆï¼Ÿ\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== é•¿è¾“å…¥åˆ†æ®µå¤„ç† ===\\n\")\n",
    "\n",
    "# 1. è¯­ä¹‰åˆ†æ®µ\n",
    "sentences = re.split(r'[ã€‚ï¼Ÿï¼]', long_input.strip())\n",
    "sentences = [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "print(f\"åŸå§‹è¾“å…¥é•¿åº¦: {len(long_input)} å­—ç¬¦\")\n",
    "print(f\"åˆ†æ®µæ•°é‡: {len(sentences)} ä¸ªè¯­ä¹‰å•å…ƒ\\n\")\n",
    "\n",
    "# 2. é€æ®µå¤„ç†\n",
    "segments_with_topics = []\n",
    "for i, sentence in enumerate(sentences):\n",
    "    # æå–å…³é”®ä¿¡æ¯\n",
    "    if \"æ•ˆç‡\" in sentence or \"ä¸è‰¯ç‡\" in sentence:\n",
    "        topic = \"ç”Ÿäº§ä¼˜åŒ–\"\n",
    "    elif \"åº“å­˜\" in sentence:\n",
    "        topic = \"åº“å­˜ç®¡ç†\"\n",
    "    elif \"è§£å†³æ–¹æ¡ˆ\" in sentence:\n",
    "        topic = \"äº§å“å’¨è¯¢\"\n",
    "    else:\n",
    "        topic = \"èƒŒæ™¯ä¿¡æ¯\"\n",
    "    \n",
    "    segments_with_topics.append({\n",
    "        \"id\": i+1,\n",
    "        \"text\": sentence,\n",
    "        \"topic\": topic\n",
    "    })\n",
    "\n",
    "print(\"ã€åˆ†æ®µç»“æœã€‘\")\n",
    "for seg in segments_with_topics:\n",
    "    print(f\"æ®µ {seg['id']} [{seg['topic']}]: {seg['text']}\")\n",
    "\n",
    "# 3. å…³é”®ç‚¹æå–\n",
    "print(\"\\nã€å…³é”®ç‚¹æå–ã€‘\")\n",
    "key_points = {\n",
    "    \"ä¼ä¸šç±»å‹\": \"æ±½è½¦é›¶éƒ¨ä»¶åˆ¶é€ \",\n",
    "    \"ä¸»è¦é—®é¢˜\": [\"ç”Ÿäº§æ•ˆç‡ä½\", \"äº§å“ä¸è‰¯ç‡ 15%\", \"åº“å­˜ç®¡ç†æ··ä¹±\"],\n",
    "    \"å’¨è¯¢æ–¹å‘\": \"å·¥ä¸šæ§åˆ¶ç³»ç»Ÿ + ERP æ•´ä½“æ–¹æ¡ˆ\",\n",
    "}\n",
    "for key, value in key_points.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# 4. å®Œæ•´æ€§æ£€æŸ¥\n",
    "print(\"\\nã€å®Œæ•´æ€§æ£€æŸ¥ã€‘\")\n",
    "all_topics = set(seg[\"topic\"] for seg in segments_with_topics)\n",
    "print(f\"æ¶µç›–çš„è¯é¢˜: {all_topics}\")\n",
    "print(\"âœ“ èƒŒæ™¯ä¿¡æ¯å®Œæ•´\")\n",
    "print(\"âœ“ é—®é¢˜ç‚¹æ¸…æ™°\")\n",
    "print(\"âœ“ å’¨è¯¢éœ€æ±‚æ˜ç¡®\")\n",
    "\n",
    "print(\"\\nâ†’ ç°åœ¨ LLM å¯ä»¥åŸºäºè¿™ä¸ªå®Œæ•´çš„èƒŒæ™¯ï¼Œç”Ÿæˆä¸€è‡´çš„ä¸“ä¸šå›ç­”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®éªŒ3ç»“æœï¼šæ¸è¿›å¼æ€»ç»“ä¸å¢é‡RAG\n",
    "\n",
    "**å®éªŒæ—¶é—´**: 2024-12-24  \n",
    "**æµ‹è¯•ä»£ç **: `experiments/test_03_v3_server.py`  \n",
    "\n",
    "#### 4ç§å¤„ç†æ–¹æ³•å¯¹æ¯”\n",
    "\n",
    "| æ–¹æ³• | ç­–ç•¥ | æ€»åˆ† | æ„ŸçŸ¥å»¶è¿Ÿ | è¯„ä»· |\n",
    "|------|------|------|----------|------|\n",
    "| M1 | Baselineï¼ˆå®Œæ•´æ–‡æœ¬ï¼‰ | 87.7/100 | 58.47s | âš ï¸ æ— å‹ç¼©ï¼Œä¸Šä¸‹æ–‡æ˜“æº¢å‡º |\n",
    "| M2 | Batch Summaryï¼ˆæ‰¹é‡æ€»ç»“ï¼‰ | 72.8/100 | 81.42s | âŒ å»¶è¿Ÿæœ€é«˜ |\n",
    "| M3 | Incremental v2ï¼ˆä»…ä¿ç•™æœ€åæ®µè½ï¼‰ | 70.2/100 | 61.14s | âŒ ä¿¡æ¯ä¸¢å¤± |\n",
    "| **M4** | **Incremental RAG v3** | **90.2/100** | **60.38s** | âœ… **ç»¼åˆæœ€ä¼˜** |\n",
    "\n",
    "#### Method 4 æ ¸å¿ƒä¼˜åŠ¿\n",
    "\n",
    "1. **æœ€é«˜ç»¼åˆè¯„åˆ†**: 90.2/100ï¼ˆä¿¡æ¯ä¿ç•™94.6ã€RAGç›¸å…³æ€§83.6ï¼‰\n",
    "2. **ä½æ„ŸçŸ¥å»¶è¿Ÿ**: æ€»ç»“å’ŒRAGéƒ½åœ¨ç”¨æˆ·è¾“å…¥è¿‡ç¨‹ä¸­å®Œæˆ\n",
    "3. **æœ€ä¼˜å‹ç¼©æ•ˆæœ**: Queryå‹ç¼©è‡³31.3%ï¼Œé¿å…ä¸Šä¸‹æ–‡æº¢å‡º\n",
    "4. **æ™ºèƒ½RAG**: å¢é‡æ£€ç´¢ + ç›¸å…³åº¦è¿‡æ»¤ï¼ˆcosine > 0.6ï¼‰+ æ–‡æ¡£å»é‡\n",
    "\n",
    "#### å¤„ç†æµç¨‹ç¤ºæ„\n",
    "\n",
    "```\n",
    "ç”¨æˆ·è¯´è¯è¿‡ç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                       â†“\n",
    "M1: æ— å¤„ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ ç­‰å¾…RAG+ç”Ÿæˆ (58.47s)\n",
    "\n",
    "M2: ç­‰å¾…è¯´å®Œ â†’ æ‰¹é‡æ€»ç»“ â†’ RAG+ç”Ÿæˆ (81.42s)\n",
    "\n",
    "M3: è¾¹è¯´è¾¹æ€»ç»“(åå°) â”€â”€â”€â”€â”€â†’ RAG+ç”Ÿæˆ (61.14s)\n",
    "    æ€»ç»“æ—¶é—´: 42.06s (éšè—)\n",
    "\n",
    "M4: è¾¹è¯´è¾¹æ€»ç»“(åå°) + å¢é‡RAG â”€â†’ æœ€ç»ˆç”Ÿæˆ (60.38s) â­\n",
    "    æ€»ç»“æ—¶é—´: 45.35s (éšè—)\n",
    "    RAGæ—¶é—´: 3.66s (åˆ†æ•£)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½å®éªŒ3ç»“æœ\n",
    "exp3_file = project_root / 'outputs' / 'experiment3_v3_server_results_20251224_131035.json'\n",
    "with open(exp3_file, 'r', encoding='utf-8') as f:\n",
    "    exp3_data = json.load(f)\n",
    "\n",
    "# å±•ç¤ºå„æ–¹æ³•çš„ç»¼åˆè¯„åˆ†\n",
    "print(\"å®éªŒ3 - é•¿éŸ³é¢‘å¤„ç†æ–¹æ³•å¯¹æ¯”\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for method_name, method_data in exp3_data['summary'].items():\n",
    "    print(f\"\\n{method_name}:\")\n",
    "    avg_scores = method_data['average_scores']\n",
    "    print(f\"  ç»¼åˆè¯„åˆ†: {avg_scores['overall']:.1f}/100\")\n",
    "    print(f\"  ä¿¡æ¯ä¿ç•™ç‡: {avg_scores['information_preservation']:.1f}\")\n",
    "    print(f\"  å™ªéŸ³è¿‡æ»¤ç‡: {avg_scores['noise_filtering']:.1f}\")\n",
    "    print(f\"  RAGç›¸å…³æ€§: {avg_scores['rag_relevance']:.1f}\")\n",
    "    print(f\"  å›å¤è´¨é‡: {avg_scores['response_quality']:.1f}\")\n",
    "    print(f\"  æ„ŸçŸ¥å»¶è¿Ÿ: {method_data['avg_total_latency']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: å®Œæ•´ Pipeline æ¼”ç¤º\n",
    "\n",
    "### ä¸‰ä¸ªè§£å†³æ–¹æ¡ˆçš„ç»„åˆæ•ˆåº”\n",
    "\n",
    "```\n",
    "å‚æ•°é€‰å‹ (Block 1)\n",
    "     â†“\n",
    "èƒ½å¦åœ¨ 500ms å†…æ¨ç†ï¼Ÿ\n",
    "     â†“\n",
    "+ RAG å¼‚æ„èåˆ (Block 2)\n",
    "     â†“\n",
    "æ˜¯å¦èƒ½è·å–å‡†ç¡®çŸ¥è¯†ï¼Ÿ\n",
    "     â†“\n",
    "+ é•¿è¾“å…¥åˆ†æ®µ (Block 3)\n",
    "     â†“\n",
    "èƒ½å¦ç†è§£å®Œæ•´éœ€æ±‚ï¼Ÿ\n",
    "     â†“\n",
    "â†’ å®ç°å®æ—¶+ä¸“ä¸šçš„ç³»ç»Ÿ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç«¯åˆ°ç«¯ Pipeline çœŸå®è°ƒç”¨\n",
    "import time\n",
    "\n",
    "# çœŸå®åœºæ™¯æµ‹è¯•\n",
    "customer_input = \"\"\"\n",
    "æˆ‘ä»¬æ˜¯ä¸€å®¶é‡‘èç§‘æŠ€å…¬å¸ï¼Œæƒ³è¦æ„å»ºå®æ—¶é£æ§ç³»ç»Ÿã€‚\n",
    "ç›®å‰ä½¿ç”¨ä¼ ç»Ÿè§„åˆ™å¼•æ“ï¼Œä½†å“åº”é€Ÿåº¦æ…¢ã€è¯¯æŠ¥ç‡é«˜ã€‚\n",
    "å¬è¯´ TechFlow æœ‰ç›¸å…³äº§å“ï¼Œèƒ½å¸®æˆ‘ä»¬åˆ†æä¸€ä¸‹å—ï¼Ÿ\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¤ å®¢æˆ·è¾“å…¥:\")\n",
    "print(customer_input)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: é•¿è¾“å…¥åˆ†æ®µï¼ˆè¿™é‡Œè¾“å…¥è¾ƒçŸ­ï¼Œæ— éœ€åˆ†æ®µï¼‰\n",
    "print(\"\\n[Step 1] é•¿è¾“å…¥å¤„ç†...\")\n",
    "segments = [s.strip() for s in customer_input.strip().split('ã€‚') if s.strip()]\n",
    "print(f\"âœ“ åˆ†æˆ {len(segments)} ä¸ªè¯­ä¹‰å•å…ƒ\")\n",
    "\n",
    "# Step 2: æ··åˆ RAG æ£€ç´¢\n",
    "print(\"\\n[Step 2] RAG å¼‚æ„æ•°æ®æ£€ç´¢...\")\n",
    "rag_start = time.time()\n",
    "rag_results, debug_info = hybrid_search(\n",
    "    customer_input, \n",
    "    bm25_idx, \n",
    "    vector_idx,\n",
    "    embedding_svc, \n",
    "    reranking_svc, \n",
    "    final_top_k=3\n",
    ")\n",
    "rag_time = time.time() - rag_start\n",
    "context = build_rag_context(rag_results)\n",
    "print(f\"âœ“ ä»çŸ¥è¯†åº“æ£€ç´¢åˆ° {len(rag_results)} æ¡ç›¸å…³ä¿¡æ¯ (è€—æ—¶: {rag_time:.3f}s)\")\n",
    "\n",
    "# Step 3: LLM æ¨ç†ï¼ˆä½¿ç”¨ 14B æ¨¡å‹ï¼‰\n",
    "print(\"\\n[Step 3] LLM æ¨ç†ï¼ˆQwen3-14Bï¼‰...\")\n",
    "llm_start = time.time()\n",
    "response = client_14b.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-14B\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯TechFlowçš„æ™ºèƒ½å®¢æœï¼Œä¸“ä¸šã€ç®€æ´ã€å®ç”¨ã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": f\"èƒŒæ™¯çŸ¥è¯†ï¼š{context}\\n\\né—®é¢˜ï¼š{customer_input}\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=500\n",
    ")\n",
    "llm_time = time.time() - llm_start\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "print(f\"âœ“ æ¨ç†å®Œæˆ (è€—æ—¶: {llm_time:.3f}s)\")\n",
    "print(\"\\nğŸ’¬ AI å›ç­”:\")\n",
    "print(\"-\" * 60)\n",
    "print(answer)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Step 4: æ€§èƒ½ç»Ÿè®¡\n",
    "print(\"\\nâ±ï¸  æ€§èƒ½ç»Ÿè®¡:\")\n",
    "e2e_latency = {\n",
    "    \"ASR\": 0.3,  # ä¼°ç®—\n",
    "    \"é•¿è¾“å…¥å¤„ç†\": 0.0,  # æœ¬ä¾‹æ— éœ€\n",
    "    \"RAGæ£€ç´¢\": rag_time,\n",
    "    \"LLMæ¨ç†\": llm_time,\n",
    "    \"TTS\": 0.4,  # ä¼°ç®—\n",
    "}\n",
    "total = sum(e2e_latency.values())\n",
    "\n",
    "for step, latency in e2e_latency.items():\n",
    "    print(f\"  {step}: {latency:.3f}s\")\n",
    "print(f\"\\nç«¯åˆ°ç«¯æ€»å»¶è¿Ÿ: {total:.3f}s\")\n",
    "print(\"âœ“ ç¬¦åˆ â‰¤1500ms ç›®æ ‡\" if total < 1.5 else \"âš ï¸ è¶…è¿‡ç›®æ ‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: æ€»ç»“ä¸è®¨è®º\n",
    "\n",
    "### å…³é”®æ”¶è·æ€»ç»“\n",
    "\n",
    "| Block | æ ¸å¿ƒé—®é¢˜ | å…³é”®è¾“å‡º |\n",
    "|-------|---------|----------|\n",
    "| Block 1 | ç”¨ä»€ä¹ˆå‚æ•°çš„ Qwenï¼Ÿ| åŒæ¨¡å‹æ¶æ„ï¼ˆ8B+14Bï¼‰ |\n",
    "| Block 2 | å¦‚ä½•å¤„ç†å¼‚æ„æ•°æ®ï¼Ÿ| æ··åˆRAGï¼ˆBM25+Dense+RRFï¼‰ |\n",
    "| Block 3 | é•¿è¾“å…¥æ€ä¹ˆä¸å‡ºé”™ï¼Ÿ| æ¸è¿›å¼æ€»ç»“+å¢é‡RAG |\n",
    "\n",
    "**æœ€ç»ˆä»·å€¼**: å‚ä¼šè€…æ‹¿èµ°å¯ç›´æ¥ç”¨äºç”Ÿäº§çš„æŠ€æœ¯æ–¹æ¡ˆå’Œä»£ç æ¡†æ¶\n",
    "\n",
    "---\n",
    "\n",
    "### å®æ–½ä¼˜å…ˆçº§\n",
    "\n",
    "1. **ä¼˜å…ˆçº§1**: é€‰å®šæ¨¡å‹è§„æ¨¡ï¼Œå®Œæˆç¡¬ä»¶è¯„ä¼°\n",
    "2. **ä¼˜å…ˆçº§2**: æ­å»ºRAGåŸºç¡€è®¾æ–½ï¼ˆæ··åˆæ£€ç´¢+Rerankingï¼‰\n",
    "3. **ä¼˜å…ˆçº§3**: é›†æˆé•¿è¾“å…¥å¤„ç†é€»è¾‘ï¼ˆæ¸è¿›å¼æ€»ç»“ï¼‰\n",
    "4. **å¯é€‰**: æ ¹æ®å®é™…æ•ˆæœï¼Œè¯„ä¼°æ˜¯å¦éœ€è¦ MoE ç­‰é«˜çº§ä¼˜åŒ–\n",
    "\n",
    "---\n",
    "\n",
    "### é£é™©æ£€æŸ¥æ¸…å•\n",
    "\n",
    "- [ ] æ¨ç†å»¶è¿Ÿæ˜¯å¦ç¨³å®š < 500msï¼Ÿ\n",
    "- [ ] RAG æ£€ç´¢çš„ç²¾åº¦ä¸å¬å›ç‡æ˜¯å¦å¯æ¥å—ï¼Ÿ\n",
    "- [ ] é•¿è¾“å…¥åˆ†æ®µæ˜¯å¦ä¿ç•™äº†å®Œæ•´ä¿¡æ¯ï¼Ÿ\n",
    "- [ ] å¹»è§‰é¢‘ç‡æ˜¯å¦åœ¨å¯æ§èŒƒå›´å†…ï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "### äº’åŠ¨ç¯èŠ‚\n",
    "\n",
    "- å‚ä¼šè€…æå‡ºçš„å…·ä½“åœºæ™¯è®¨è®º\n",
    "- é’ˆå¯¹æ€§çš„æ¨¡å‹é€‰æ‹©å»ºè®®\n",
    "- Q&A æ—¶é—´\n",
    "\n",
    "---\n",
    "\n",
    "## å‚è€ƒèµ„æ–™\n",
    "\n",
    "- **å®éªŒç»“æœè¯¦æƒ…**: [docs/EXPERIMENT3_RESULTS.md](../docs/EXPERIMENT3_RESULTS.md)\n",
    "- **vLLMéƒ¨ç½²æŒ‡å—**: [docs/LOCAL_VLLM_GUIDE.md](../docs/LOCAL_VLLM_GUIDE.md)\n",
    "- **å®Œæ•´ç³»ç»Ÿæ–‡æ¡£**: [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## é™„å½•ï¼švLLM æœåŠ¡ç®¡ç†\n",
    "\n",
    "### æŸ¥çœ‹ vLLM æœåŠ¡æ—¥å¿—\n",
    "\n",
    "å¦‚æœæœåŠ¡å¯åŠ¨å¤±è´¥æˆ–è¿è¡Œå¼‚å¸¸ï¼Œå¯ä»¥æŸ¥çœ‹æ—¥å¿—ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# æŸ¥çœ‹ Qwen3-8B æœ€è¿‘çš„æ—¥å¿—\n",
    "echo \"=== Qwen3-8B (ç«¯å£ 8000) æ—¥å¿— ===\"\n",
    "tail -30 logs/vllm_8b.log\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Qwen3-14B (ç«¯å£ 8001) æ—¥å¿— ===\"\n",
    "tail -30 logs/vllm_14b.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åœæ­¢ vLLM æœåŠ¡\n",
    "\n",
    "Workshop ç»“æŸåï¼Œå¯ä»¥åœæ­¢ vLLM æœåŠ¡é‡Šæ”¾ GPU èµ„æºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# åœæ­¢æ‰€æœ‰vLLMè¿›ç¨‹\n",
    "pkill -f \"vllm.entrypoints.openai.api_server\"\n",
    "echo \"âœ“ vLLM æœåŠ¡å·²åœæ­¢\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}