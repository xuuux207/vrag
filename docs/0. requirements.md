# 虚拟销售/客服系统需求文档

## 项目背景
下个月还得麻烦一场workshop，具体的信息如下。这次的一家企业是做虚拟销售/客服的一家企业，他们使用ASR/TTS+LLM做电话销售和客户。

## 核心技术指标

### 1. VAD (语音活动检测)
- 客户讲了半句停顿不再说话的处理
- 客户讲完整句停顿，不再说话不再回应的处理
- 客户主动打断AI话语的处理

### 2. 全链路延迟要求
- **目标延迟**: ≤1500ms (端到端)
- 其中LLM输入输出时间: ≤500ms
- 实际响应时间预计: 1.2~2秒

### 3. 大模型专业性要求
- 交互轮次: **30轮以内**结束
- 避免显著幻觉和"答非所问"
- 客户问答互动普遍集中于专业内容(产品、案例、解决方案)
- 应用场景参考: 客户咨询微软Azure
- LLM专业度提升方案: **MoE路由架构** (按行业或产品类型划分)

## 系统架构

### 级联方案
模型串联顺序: **VAD → ASR → LLM → TTS**

### LLM选型
- 基础模型: **Qwen3系列**
- 需要确定的参数规模 (训练 vs 推理)
- 需要评估MoE架构的必要性

## 核心问题

### 问题1: 模型参数选择
**如果要兼顾实时性和专业性，我们应该分别选用什么参数的LLM模型进行训练和推理？**

考虑因素:
- LLM输入输出时间 ≤500ms
- 显卡算力要求的天花板
- 训练模型 vs 推理模型的参数差异

### 问题2: RAG与知识库方案
**针对异构数据源的知识整合方案:**

数据源特征:
- **左手**: 企业图谱类数据 (类似天眼查、企查查的结构化数据)
- **右手**: 乙方业务材料 (以西门子为例)
  - 文档类型: Word、PPT、PDF
  - 内容形式: 文本、图片为主
  - 特点: 耦合性不强的文档

核心问题:
- RAG和知识库应该如何设计？
- 有没有什么方案可以形成**有效的炼丹炉**？
- 如何处理结构化数据与非结构化文档的融合？

### 问题3: MoE路由与长输入处理
**场景**: 客户说话时间超过40秒或60秒，巴拉巴拉讲了一大堆

挑战:
- 一次性输入太多
- 可能跨多个MoE专家领域
- 需要保证实时性的同时避免幻觉

问题: LLM有什么应对方案？

## 待确认事项
- [ ] Qwen3具体参数规模的选择 (训练/推理)
- [ ] 是否采用MoE架构
- [ ] MoE路由策略设计
- [ ] RAG与知识库的技术方案
- [ ] 长输入的切分与处理策略
- [ ] 显卡算力需求评估
