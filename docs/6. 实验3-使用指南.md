# 实验3：长时间语音输入的分段总结与RAG处理

## 📋 实验概述

本实验旨在解决**用户长时间语音输入后如何更准确回复**的问题，通过**分段总结 + 结构化提取 + RAG检索**的方式，提升长文本查询的处理效果。

### 核心问题

在实际语音交互中，用户可能进行2-5分钟的长语音输入，导致：
- 转文本后有500-2000字
- 包含多个主题和意图
- 直接RAG检索效果不佳（query过长）
- 关键信息被淹没在细节中

### 解决方案

**方案对比：**

| 方法 | 流程 | 优点 | 缺点 |
|------|------|------|------|
| **Baseline** | 长文本 → RAG检索 → 生成 | 简单快速 | 检索精度低 |
| **Pipeline**（本实验） | 长文本 → 结构化提取 → 简化query → RAG → 生成 | 检索精度高、信息完整 | 延迟稍高 |

---

## 📁 文件结构

```
experiments/
├── long_audio_test_cases.json            # 10个测试用例
├── long_audio_simulator.py               # 长语音模拟器
├── long_audio_rag_pipeline.py            # 核心处理流程
└── test_03_long_audio_rag.py             # 主测试脚本

docs/
└── 5. 实验3-长语音理解实验设计.md       # 完整设计文档

outputs/
├── experiment3_long_audio_results_*.json # 测试结果
└── experiment3_long_audio_report_*.md    # 分析报告
```

---

## 🚀 快速开始

### 前置条件

1. **vLLM服务已启动**（本地或远程）
   ```bash
   # 本地启动（如果还没启动）
   cd ~/tts
   bash scripts/start_local_services.sh

   # 或者SSH到服务器
   ssh azure-a100
   cd ~/tts
   bash scripts/start_local_services.sh
   ```

2. **环境变量配置**
   确保 `.env` 文件包含：
   ```bash
   EMBEDDING_TOKEN=your_token
   EMBEDDING_URL=https://api.siliconflow.cn/v1/embeddings
   EMBEDDING_MODEL=BAAI/bge-m3
   RERANK_TOKEN=your_token
   RERANK_URL=https://api.siliconflow.cn/v1/rerank
   RERANK_MODEL=BAAI/bge-reranker-v2-m3
   ```

### 运行实验

#### 本地运行（vLLM在本机）

```bash
cd ~/tts
uv run python experiments/test_03_long_audio_rag.py
```

#### 远程运行（vLLM在服务器）

```bash
# 1. 上传代码到服务器
rsync -avz /local/tts/ azure-a100:~/tts/

# 2. SSH到服务器
ssh azure-a100

# 3. 运行实验
cd ~/tts
source ~/miniconda3/bin/activate
python3 experiments/test_03_long_audio_rag.py

# 4. 下载结果
exit
rsync -avz azure-a100:~/tts/outputs/experiment3_long_audio_* ./outputs/
```

---

## 📊 测试用例

本实验包含10个精心设计的测试用例，涵盖多种场景：

| ID | 类别 | 文本长度 | 特点 |
|----|------|---------|------|
| `complex_product_inquiry` | 复杂产品咨询 | 218字 | 多个需求点、约束条件 |
| `multi_question_technical` | 多问题技术咨询 | 180字 | 5个独立问题 |
| `redundant_information` | 冗余信息过滤 | 150字 | 大量口语化表达 |
| `customer_background_inquiry` | 客户背景查询 | 160字 | 需要查询历史案例 |
| `product_recommendation_with_context` | 产品推荐 | 190字 | 详细痛点描述 |
| `competitor_customer_inquiry` | 竞品客户识别 | 170字 | 多企业对比 |
| `detailed_requirement_description` | 详细需求描述 | 240字 | 复杂业务场景 |
| `comparison_inquiry` | 多企业对比查询 | 150字 | 3家企业对比 |
| `vague_inquiry` | 模糊咨询 | 140字 | 需求不明确 |
| `urgent_inquiry` | 紧急需求咨询 | 200字 | 时间压力 |

---

## 📈 评估指标

实验会对比两种方法（Baseline vs Pipeline）的以下指标：

| 指标 | 说明 | 权重 |
|------|------|------|
| **信息保留率** | 关键信息是否被提取 | 30% |
| **RAG召回率** | 是否召回正确文档 | 25% |
| **RAG精确率** | 返回文档的相关性 | 25% |
| **回复质量** | LLM评分（1-10分） | 20% |

---

## 🎯 预期结果

根据设计文档，预期改进如下：

| 指标 | Baseline | Pipeline | 改进 |
|------|---------|----------|------|
| 信息保留率 | 60% | **90%** | +30% |
| RAG召回率 | 40% | **75%** | +35% |
| 回复质量 | 6.5/10 | **8.5/10** | +2分 |
| 处理延迟 | 1.5s | **2.5s** | +1s |

---

## 📝 结果分析

运行完成后，会生成两个文件：

1. **JSON结果** (`experiment3_long_audio_results_*.json`)
   - 每个测试用例的详细数据
   - Baseline vs Pipeline的对比
   - 时间统计、评分详情

2. **Markdown报告** (`experiment3_long_audio_report_*.md`)
   - 整体统计对比
   - 分类别结果分析
   - 详细测试用例展示
   - 结论与优化建议

---

## 🔧 调试与测试

### 单独测试组件

#### 1. 测试长语音模拟器

```bash
uv run python experiments/long_audio_simulator.py
```

#### 2. 测试Pipeline（单个case）

```python
from experiments.long_audio_rag_pipeline import LongAudioRAGPipeline
from openai import OpenAI

llm = OpenAI(api_key="EMPTY", base_url="http://localhost:8000/v1")
# ... 初始化其他组件

pipeline = LongAudioRAGPipeline(llm, vector_index, ...)
result = pipeline.process("你的测试文本...")
print(result)
```

### 常见问题

1. **vLLM连接失败**
   ```bash
   # 检查服务状态
   curl http://localhost:8000/v1/models

   # 查看日志
   tail -f logs/vllm.log
   ```

2. **Embedding API超时**
   - 检查 `.env` 中的token是否正确
   - 测试API连接：
     ```bash
     curl -X POST "$EMBEDDING_URL" \
       -H "Authorization: Bearer $EMBEDDING_TOKEN" \
       -H "Content-Type: application/json" \
       -d '{"model":"BAAI/bge-m3","input":["测试"]}'
     ```

3. **JSON解析失败**
   - LLM返回的JSON可能包含markdown标记
   - 代码中已做处理，但如果仍失败，检查LLM输出格式

---

## 🎓 扩展实验

### 实验变体

1. **渐进式总结**（实时场景）
   - 边听边总结
   - 适合实时交互

2. **多模型对比**
   - 测试不同LLM的提取效果
   - Qwen3-8B vs 14B vs 32B

3. **不同总结策略**
   - 简单摘要 vs 结构化提取 vs 多query分解
   - 评估哪种策略最优

---

## 📚 参考文档

- [设计文档](5.%20实验3-长语音理解实验设计.md) - 完整的方案设计
- [准备总结](7.%20实验3-准备总结.md) - 准备工作总结
- [实验1报告](3.%20实验1-模型对比设计.md) - 模型对比基准
- [实验2报告](4.%20实验2-RAG融合设计.md) - RAG优化方案

---

## 🤝 贡献

如果你有改进建议或发现问题，欢迎：
1. 修改测试用例（`long_audio_test_cases.json`）
2. 优化Prompt模板（`long_audio_rag_pipeline.py`）
3. 添加新的评估指标

---

**实验设计**: 2025-12-20
**作者**: Haoquan + Claude Sonnet 4.5
